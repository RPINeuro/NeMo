Automatically generated by Mendeley Desktop 1.13.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@inproceedings{Khosravi2012,
abstract = {Software product line engineering enables strategic reuse in development of families of related products. In a component-based approach to product line development, components capture functionalities appearing in one or more products in the family and different assemblies of components yield to various products or configurations. In this approach, an interaction model which effectively factors out the logic handling variability from the functionality of the system greatly enhances the reusability of components. We study the problem of variability modeling for a family of distributed systems expressed in actor model. We define a special type of actors called coordinators whose behavior is described as Reo circuits with the aim of encapsulating the variability logic. We have the benefits of Reo language for expressing coordination logic, while modeling the entire system as an actor-based distributed model. We have applied this model to a case study extracted from an industrial software family in the domain of interactive TV.},
author = {Khosravi, Ramtin and Sabouri, Hamideh},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-30829-1\_6},
isbn = {9783642308284},
issn = {03029743},
pages = {74--88},
title = {{Using coordinated actors to model families of distributed systems}},
volume = {7274 LNCS},
year = {2012}
}
@book{Hermanowicz2003,
address = {New York},
author = {Hermanowicz, Joseph},
isbn = {9780875861890},
publisher = {Agathon Press},
title = {{College attrition at American research universities: comparative case studies}},
year = {2003}
}
@article{Dorier2014,
author = {Dorier, Matthieu and Ibrahim, Shadi and Antoniu, Gabriel and Ross, Rob},
doi = {10.1109/SC.2014.56},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/Supercomputing/Dorier et al/Dorier et al.\_2014\_Omnisc ’ IO A Grammar-Based Approach to Spatial and Temporal I O Patterns Prediction\_Supercomputing.pdf:pdf},
isbn = {978-1-4799-5500-8},
journal = {Supercomputing},
keywords = {exascale,grammar,hpc,i,o,prediction,storage},
title = {{Omnisc ’ IO : A Grammar-Based Approach to Spatial and Temporal I / O Patterns Prediction}},
year = {2014}
}
@article{Martinez2007,
author = {Mart\'{\i}nez, Sonia and Cort\'{e}s, Jorge and Bullo, Francesco},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2007/IEEE Control Systems Magazine/Mart\'{\i}nez, Cort\'{e}s, Bullo/Mart\'{\i}nez, Cort\'{e}s, Bullo\_2007\_Motion coordination with Distributed Information\_IEEE Control Systems Magazine.pdf:pdf},
journal = {IEEE Control Systems Magazine},
pages = {75--88},
title = {{Motion coordination with Distributed Information}},
year = {2007}
}
@article{AL-Allaf2012,
author = {AL-Allaf, ONA},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/Lecture Notes in Engineering and Computer Science/AL-Allaf/AL-Allaf\_2012\_Cascade-Forward vs. Function Fitting Neural Network for Improving Image Quality and Learning Time in Image Compression Sys.pdf:pdf},
isbn = {9789881925213},
journal = {Lecture Notes in Engineering and Computer Science},
title = {{Cascade-Forward vs. Function Fitting Neural Network for Improving Image Quality and Learning Time in Image Compression System}},
url = {http://www.iaeng.org/publication/WCE2012/WCE2012\_pp1172-1178.pdf},
volume = {II},
year = {2012}
}
@article{Kothari2012,
author = {Kothari, Arati},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/Unknown/Kothari/Kothari\_2012\_Detection and classification of brain cancer using artificial neural network in MRI images\_Unknown.pdf:pdf},
keywords = {ann,brain cancer,co-occurrence matrix,glcm,mri},
number = {5},
pages = {1--4},
title = {{Detection and classification of brain cancer using artificial neural network in MRI images}},
volume = {2},
year = {2012}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/Mendeley Desktop/The Mendeley Support Team/The Mendeley Support Team\_2011\_Getting Started with Mendeley\_Mendeley Desktop.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Yang2000,
author = {Yang, C and Prasher, S O and Landry, J and Ramaswamy, H S and Ditommaso, A},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2000/Unknown/Yang et al/Yang et al.\_2000\_Application of artificial neural networks in image recognition and classification of crop and weeds\_Unknown.pdf:pdf},
number = {September},
pages = {147--152},
title = {{Application of artificial neural networks in image recognition and classification of crop and weeds}},
year = {2000}
}
@inproceedings{Kumar2014a,
abstract = {We present an efficient, flexible, adaptive-resolution I/O framework that is suitable for both uniform and Adaptive Mesh Refinement (AMR) simulations. In an AMR setting, current solutions typically represent each resolution level as an independent grid which often results in inefficient storage and performance. Our technique coalesces domain data into a unified, multiresolution representation with fast, spatially aggregated I/O. Furthermore, our framework easily extends to importance-driven storage of uniform grids, for example, by storing regions of interest at full resolution and nonessential regions at lower resolution for visualization or analysis. Our framework, which is an extension of the PIDX framework, achieves state of the art disk usage and I/O performance regardless of resolution of the data, regions of interest, and the number of processes that generated the data. We demonstrate the scalability and efficiency of our framework using the Uintah and S3D large-scale combustion codes on the Mira and Edison supercomputers.},
address = {New Orleans},
author = {Kumar, Sidharth and Edwards, John and Bremer, Peer-timo and Knoll, Aaron and Christensen, Cameron and Vishwanath, Venkatram and Carns, Philip and Schmidt, John A and Pascucci, Valerio},
booktitle = {SC14: International Conference for High Performance Computing, Networking, Storage and Analysis},
doi = {10.1109/SC.2014.39},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/SC14 International Conference for High Performance Computing, Networking, Storage and Analysis/Kumar et al/Kumar et al.\_2014\_Efficient I O and Storage of Adaptive-Resolution Data\_SC14 International Conference for High Performance Computing, N.pdf:pdf},
isbn = {9781479955008},
keywords = {AMR setting,AMR simulation,Adaptation models,Arrays,Data models,Edison supercomputer,Encoding,I/O performance,Indexes,Layout,Lecture 13,Mira supercomputer,PIDX framework,S3D large-scale combustion code,Spatial resolution,Uintah,adaptive mesh refinement simulation,adaptive-resolution I/O framework,adaptive-resolution data,data resolution,data structures,disk usage,domain data,grid computing,importance-driven storage,independent grid,input-output programs,lower resolution,multiresolution representation,parallel machines,regions of interest,resolution level,uniform grid},
mendeley-tags = {Lecture 13},
pages = {413--423},
publisher = {IEEE},
title = {{Efficient I / O and Storage of Adaptive-Resolution Data}},
year = {2014}
}
@techreport{Bogard,
abstract = {Literature indicates that data mining or algorithmic approaches to prediction can provide superior results vis-\`{a}-vis traditional statistical modeling approaches (Delen et al, 2004; Sharda and Delen, 2006; Delen et al, 2007; Kiang 2007; Li et al 2009). However, little research in higher education has focused on the employment of data mining methods for predicting retention. Using three years of data for first time first year degree seeking students we compared results from logistic regression, decision trees, neural networks, and ensemble models implemented using SAS Enterprise Miner. Based on validation misclassification rates and robustness, decision trees were chosen for the final model specification. Building models for three time periods (pre-enrollment or 1 st day of term, 5 th week of term, and end of term) the predictive accuracy of our decision trees improved with each shift in time. The score code generated from SAS Enterprise Miner will make it possible to create custom reports with color coded risk indicators within the SAS BI decision support system. This will enable administrators, advisors, professors and other higher education professionals within the institution to incorporate advanced analytics into retention efforts.},
author = {Bogard, Matt and Helbig, Tuesdi and Huff, Gina and James, Chris},
booktitle = {wku.edu},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/wku.edu/Bogard et al/Bogard et al.\_2011\_A Comparison of Empirical Models for Predicting Student Retention\_wku.edu.pdf:pdf},
institution = {Office of Institutional Research, Western Kentucky University},
keywords = {data mining,decision trees,sas enterprise miner,student retention},
title = {{A Comparison of Empirical Models for Predicting Student Retention}},
url = {http://www.wku.edu/instres/documents/comparison\_of\_empirical\_models.pdf},
year = {2011}
}
@inproceedings{Chen2009,
abstract = {Inﬂuence maximization is the problem of ﬁnding a small subset of nodes (seed nodes) in a social network that could maximize the spread of inﬂuence. In this paper, we study the efﬁcient inﬂuence maximization from two complementary directions. One is to improve the original greedy algorithm of [5] and its improvement [7] to further reduce its running time, and the second is to propose new degree discount heuristics that improves inﬂuence spread. We evaluate our algorithms by experiments on two large academic collaboration graphs obtained from the online archival database arXiv.org. Our experimental results show that (a) our improved greedy algorithm achieves better running time comparing with the improvement of [7] with matching inﬂuence spread, (b) our degree discount heuristics achieve much better inﬂuence spread than classic degree and centrality-based heuristics, and when tuned for a speciﬁc inﬂuence cascade model, it achieves almost matching inﬂuence thread with the greedy algorithm, and more importantly (c) the degree discount heuristics run only in milliseconds while even the improved greedy algorithms run in hours in our experiment graphs with a few tens of thousands of nodes. Based on our results, we believe that ﬁne-tuned heuristics may provide truly scalable solutions to the inﬂuence maximization problem with satisfying inﬂuence spread and blazingly fast running time. Therefore, contrary to what implied by the conclusion of [5] that traditional heuristics are outperformed by the greedy approximation algorithm, our results shed new lights on the research of heuristic algorithms.},
author = {Chen, Wei and Wang, Yajun and Yang, Siyu},
booktitle = {KDD},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2009/KDD/Chen, Wang, Yang/Chen, Wang, Yang\_2009\_Efﬁcient Inﬂuence Maximization in Social Networks\_KDD.pdf:pdf},
title = {{Efﬁcient Inﬂuence Maximization in Social Networks}},
year = {2009}
}
@inproceedings{domingos2001mining,
author = {Domingos, Pedro and Richardson, Matt},
booktitle = {Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining},
organization = {ACM},
pages = {57--66},
title = {{Mining the network value of customers}},
year = {2001}
}
@misc{Harris,
author = {Harris, Derrick},
keywords = {andrew ng,artificial intelligence,big data,cloud,data,deep learning,fpga,geoffrey fox,jack dongarra,machine-learning,national science foundation,python,rdma,supercomputers},
title = {{Researchers hope deep learning algorithms can run on FPGAs and supercomputers — Tech News and Analysis}},
url = {http://gigaom.com/2014/08/14/researchers-hope-deep-learning-algorithms-can-run-on-fpgas-and-supercomputers/},
urldate = {2014-08-15}
}
@article{Budden2010,
abstract = {Using a sample of 2,137 university students and applying the logit model, we find that the probability for students to return in fall 2008 is higher with a higher cumulative GPA, a higher grade for SE 101, and a returning status in the previous semester. Several other explanatory variables are tested and have insignificant coefficients. A few variables such as the Board of Regent’s core requirements (CORE) and high school graduating GPA (HSGPA) have the expected signs and z-statistics closer to one, suggesting that the correlation coefficient may rise if the sample size were larger. The findings suggest that the cumulative GPA is a dominant factor and that the large number of failures in SE 101 may need to be examined in order to fulfill its described purpose: “a course designed to ensure first-year student success.”},
author = {Budden, Michael C and Hsing, Yu and Budden, Connie B and Hall, Michelle},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2010/Contemporary Issues In Education Research/Budden et al/Budden et al.\_2010\_Heads Or Tails ( Success Or Failure ) Using Logit Modeling To Predict Student Retention And Progression\_Contemporary.pdf:pdf},
journal = {Contemporary Issues In Education Research},
keywords = {graduation rates,logit,persistence,progression,retention},
number = {5},
pages = {35--42},
title = {{Heads Or Tails ( Success Or Failure )? Using Logit Modeling To Predict Student Retention And Progression}},
volume = {3},
year = {2010}
}
@article{Ahrens2014a,
author = {Ahrens, James and Leary, Patrick O and Patchett, John and Rogers, David H and Petersen, Mark},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/SC14 International Conference for High Performance Computing, Networking, Storage and Analysis/Ahrens et al/Ahrens et al.\_2014\_An Image-based Approach to Extreme Scale In Situ Visualization and Analysis\_SC14 International Conference for High Pe.pdf:pdf},
isbn = {9781479955008},
journal = {SC14: International Conference for High Performance Computing, Networking, Storage and Analysis},
keywords = {Lecture 13},
mendeley-tags = {Lecture 13},
title = {{An Image-based Approach to Extreme Scale In Situ Visualization and Analysis}},
year = {2014}
}
@article{Nageswaran2009,
abstract = {Neural network simulators that take into account the spiking behavior of neurons are useful for studying brain mechanisms and for various neural engineering applications. Spiking Neural Network (SNN) simulators have been traditionally simulated on large-scale clusters, super-computers, or on dedicated hardware architectures. Alternatively, Compute Unified Device Architecture (CUDA) Graphics Processing Units (GPUs) can provide a low-cost, programmable, and high-performance computing platform for simulation of SNNs. In this paper we demonstrate an efficient, biologically realistic, large-scale SNN simulator that runs on a single GPU. The SNN model includes Izhikevich spiking neurons, detailed models of synaptic plasticity and variable axonal delay. We allow user-defined configuration of the GPU-SNN model by means of a high-level programming interface written in C++ but similar to the PyNN programming interface specification. PyNN is a common programming interface developed by the neuronal simulation community to allow a single script to run on various simulators. The GPU implementation (on NVIDIA GTX-280 with 1 GB of memory) is up to 26 times faster than a CPU version for the simulation of 100K neurons with 50 Million synaptic connections, firing at an average rate of 7 Hz. For simulation of 10 Million synaptic connections and 100K neurons, the GPU SNN model is only 1.5 times slower than real-time. Further, we present a collection of new techniques related to parallelism extraction, mapping of irregular communication, and network representation for effective simulation of SNNs on GPUs. The fidelity of the simulation results was validated on CPU simulations using firing rate, synaptic weight distribution, and inter-spike interval analysis. Our simulator is publicly available to the modeling community so that researchers will have easy access to large-scale SNN simulations.},
author = {Nageswaran, Jayram Moorkanikara and Dutt, Nikil and Krichmar, Jeffrey L. and Nicolau, Alex and Veidenbaum, Alexander V.},
doi = {10.1016/j.neunet.2009.06.028},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2009/Neural Networks/Nageswaran et al/Nageswaran et al.\_2009\_A configurable simulation environment for the efficient simulation of large-scale spiking neural networks on grap.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {CUDA,Data parallelism,Graphics processor,Izhikevich spiking neuron,STDP},
number = {5-6},
pages = {791--800},
pmid = {19615853},
publisher = {Elsevier Ltd},
title = {{A configurable simulation environment for the efficient simulation of large-scale spiking neural networks on graphics processors}},
url = {http://dx.doi.org/10.1016/j.neunet.2009.06.028},
volume = {22},
year = {2009}
}
@article{January2012,
author = {January, Huw Evans},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/Unknown/January/January\_2012\_A toad's guide to using Scrivener – MultiMarkDown – Latex\_Unknown.pdf:pdf},
title = {{A toad's guide to using Scrivener – MultiMarkDown – Latex}},
year = {2012}
}
@article{SINGH2012,
author = {Singh, S and Jokhan, A and Sharma, B and Lal, S},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/Journal of Machine Learning Technologies/Singh et al/Singh et al.\_2012\_An Innovative Approach Of Progressive Feedback via Artificial Neural Networks\_Journal of Machine Learning Technologies.pdf:pdf},
journal = {Journal of Machine Learning Technologies},
keywords = {- self-organizing map,-64-70,2012,2012 sharma b,2229-3981,2229-399x,an innovative approach of,article distributed under the,artificial neural network,citation,commons attribu-,computers and education,copyright,e-learning,e-planning,et al,issn,issue 1,journal of machine,k-means clustering,learning technologies,neural networks,pp,progressive feedback via artificial,sharma b,terms of the creative,this is an open-access,volume 3},
number = {1},
pages = {64--70},
title = {{An Innovative Approach Of Progressive Feedback via Artificial Neural Networks}},
url = {http://www.bioinfo.in/uploadfiles/13312817243\_1\_1\_JMLT.pdf},
volume = {3},
year = {2012}
}
@misc{Dinh2013,
abstract = {Online social networks (OSNs) have become one of the most effective channels for marketing and advertising. Since users are often influenced by their friends, “word-of-mouth” exchanges, so-called viral marketing, in social networks can be used to increase product adoption or widely spread content over the network. The common perception of viral marketing about being cheap, easy, and massively effective makes it an ideal replacement of traditional advertising. However, recent studies have revealed that the propagation often fades quickly within only few hops from the sources, counteracting the assumption on the self-perpetuating of influence considered in literature. With only limited influence propagation, is massively reaching customers via viral marketing still affordable? How do we economically spend more resources to increase the spreading speed? We investigate the cost-effective massive viral marketing problem, taking into the consideration the limited influence propagation. Both analytical analysis based on power-law network theory and numerical analysis demonstrate that the viral marketing might involve costly seeding. To minimize the seeding cost, we provide mathematical programming to find optimal seeding for medium-size networks and propose VirAds, an efficient algorithm, to tackle the problem on large-scale networks. VirAds guarantees a relative error bound of \$O(1)\$ from the optimal solutions in power-law networks and outperforms the greedy heuristics that realizes on the degree centrality. Moreover, we also show that, in general, approximating the optimal seeding within a ratio better than \$O(log n)\$ is unlikely possible.},
author = {Dinh, Thang N. and Zhang, Huiyuan and Nguyen, Dung T. and Thai, My T.},
booktitle = {IEEE/ACM Transactions on Networking},
doi = {10.1109/TNET.2013.2290714},
issn = {10636692},
title = {{Cost-Effective Viral Marketing for Time-Critical Campaigns in Large-Scale Social Networks}},
year = {2013}
}
@inproceedings{Zounmevo2014,
author = {Zounmevo, Judicael A and Zhao, Xin and Balaji, Pavan and Gropp, William and Afsahi, Ahmad},
booktitle = {SC14: International Conference for High Performance Computing, Networking, Storage and Analysis},
doi = {10.1109/SC.2014.44},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/SC14 International Conference for High Performance Computing, Networking, Storage and Analysis/Zounmevo et al/Zounmevo et al.\_2014\_Nonblocking Epochs in MPI One-Sided Communication\_SC14 International Conference for High Performance Computing, Net.pdf:pdf},
isbn = {978-1-4799-5500-8},
keywords = {latency propagation,mpi,nonblocking synchroniza-,one-sided,rma,tions},
number = {1},
pages = {475--486},
title = {{Nonblocking Epochs in MPI One-Sided Communication}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7013026},
year = {2014}
}
@article{year,
title = {{No Title}}
}
@article{Oa,
author = {\'{O}\'{a}, T and V\"{u}, \c{C}},
title = {{§ \^{A} D ¢ \"{y} \"{U} d o g « d  x ¬ n  V ¬ z ¢ d \^{O} g ¡ i ¨ d ¡ \'{Y} \^{U} y \`{O} ¿ Þ n ¦ P ² g § p ¬ m \'{E} d  f \^{E} b \`{O} T ¨ z § b ¬ d  s ¾ V ¬ T ¢ o ¬ z § y  d \~{A} y \~{A}   \`{U} © d g  s ¨ x « n ¬ \ss \`{I} T \'{E} d  \"{E} ¡ F \^{E} ` \`{O} y \'{E} d \`{E} `  z  \`{A} ¬ E ¢ g ¡ y § \AA  \ss \'{y} ¨ \"{u} u \^{u} ¦ \'{u} \`{A} \`{u} \o}}
}
@article{Cassidy2013,
abstract = {Marching along the DARPA SyNAPSE roadmap, IBM unveils a trilogy of innovations towards the TrueNorth cognitive computing system inspired by the brain's function and efficiency. Judiciously balancing the dual objectives of functional capability and implementation/operational cost, we develop a simple, digital, reconfigurable, versatile spiking neuron model that supports one-to-one equivalence between hardware and simulation and is implementable using only 1272 ASIC gates. Starting with the classic leaky integrate-and-fire neuron, we add: (a) configurable and reproducible stochasticity to the input, the state, and the output; (b) four leak modes that bias the internal state dynamics; (c) deterministic and stochastic thresholds; and (d) six reset modes for rich finite-state behavior. The model supports a wide variety of computational functions and neural codes. We capture 50+ neuron behaviors in a library for hierarchical composition of complex computations and behaviors. Although designed with cognitive algorithms and applications in mind, serendipitously, the neuron model can qualitatively replicate the 20 biologically-relevant behaviors of a dynamical neuron model.},
author = {Cassidy, Andrew S. and Merolla, Paul and Arthur, John V. and Esser, Steve K. and Jackson, Bryan and Alvarez-Icaza, Rodrigo and Datta, Pallab and Sawada, Jun and Wong, Theodore M. and Feldman, Vitaly and Amir, Arnon and Rubin, Daniel Ben Dayan and Akopyan, Filipp and McQuinn, Emmett and Risk, William P. and Modha, Dharmendra S.},
doi = {10.1109/IJCNN.2013.6707077},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2013/Proceedings of the International Joint Conference on Neural Networks/Cassidy et al/Cassidy et al.\_2013\_Cognitive computing building block A versatile and efficient digital neuron model for neurosynaptic cores\_Proceeding.pdf:pdf},
isbn = {9781467361293},
journal = {Proceedings of the International Joint Conference on Neural Networks},
title = {{Cognitive computing building block: A versatile and efficient digital neuron model for neurosynaptic cores}},
year = {2013}
}
@book{Pulsipher2012,
address = {New Yourk},
author = {Pulsipher, Lydia M. and Pulsipher, Alex},
edition = {Second Edi},
publisher = {W.H. Freeman and Company},
title = {{World Regional Geography}},
year = {2012}
}
@article{Durham,
author = {Durham, Joesph},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/Unknown/Unknown/Durham/Durham\_Unknown\_Discrete Partitioning and Coverage Control for Gossiping Robots\_Unknown.pdf:pdf},
title = {{Discrete Partitioning and Coverage Control for Gossiping Robots}}
}
@inproceedings{Wang,
author = {Wang, Yu and Cong, Gao and Song, Guojie and Xie, Kunquing},
booktitle = {Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining},
pages = {1039--1048},
title = {{Community-based Greedy Algorithm for Mining Top-K Influential Nodes in Mobile Social Networks}},
url = {http://users.cis.fiu.edu/~lzhen001/activities/KDD\_USB\_key\_2010/docs/p1039.pdf},
year = {2010}
}
@article{Varela2001,
author = {Varela, Carlos and Agha, Gul},
doi = {10.1145/583960.583964},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2001/ACM SIGPLAN Notices/Varela, Agha/Varela, Agha\_2001\_Programming dynamically reconfigurable open systems with SALSA\_ACM SIGPLAN Notices.pdf:pdf},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {0,0 d,1,1 3,1 5 g3q,3 k f b3,5,5i,b,cd,d,ed,eg 5 b,f5 5,g,g gd,g w ii,i,if x5xi 5 d,iq,p,t,w,wxi i,x},
month = dec,
number = {12},
pages = {20},
title = {{Programming dynamically reconfigurable open systems with SALSA}},
url = {http://portal.acm.org/citation.cfm?doid=583960.583964},
volume = {36},
year = {2001}
}
@article{Gim2014,
author = {Gim, Alfredo and Gamblin, Todd and Rountree, Barry and Bhatele, Abhinav and Jusufi, Ilir},
doi = {10.1109/SC.2014.19},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/Submission to VizSC/Gim et al/Gim et al.\_2014\_Dissecting On-Node Memory Access Performance A Semantic Approach\_Submission to VizSC.pdf:pdf},
isbn = {978-1-4799-5500-8},
journal = {Submission to Viz/SC},
title = {{Dissecting On-Node Memory Access Performance : A Semantic Approach}},
year = {2014}
}
@article{Lobb2005,
abstract = { Neural systems are composed of a large number of highly-connected neurons and are widely simulated within the neurological community. In this paper, we examine the application of parallel discrete event simulation techniques to networks of a complex model called the Hodgkin-Huxley neuron. We describe the conversion of this model into an event-driven simulation, a technique that offers the potential of much greater performance in parallel and distributed simulations compared to time-stepped techniques. We report results of an initial set of experiments conducted to determine the feasibility of this parallel event-driven Hodgkin-Huxley model and analyze its viability for large-scale neural simulations.},
author = {Lobb, Collin J. and Chao, Zenas and Fujimoto, Richard M. and Potter, Steve M.},
doi = {10.1109/PADS.2005.18},
isbn = {0-7695-2383-8},
issn = {1087-4097},
journal = {Proceedings - Workshop on Principles of Advanced and Distributed Simulation, PADS},
pages = {16--25},
title = {{Parallel event-driven neural network simulations using the Hodgkin-Huxley neuron model}},
year = {2005}
}
@article{merolla2014million,
author = {Merolla, Paul A and Arthur, John V and Alvarez-Icaza, Rodrigo and Cassidy, Andrew S and Sawada, Jun and Akopyan, Filipp and Jackson, Bryan L and Imam, Nabil and Guo, Chen and Nakamura, Yutaka and Others},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/Science/Merolla et al/Merolla et al.\_2014\_A million spiking-neuron integrated circuit with a scalable communication network and interface\_Science.pdf:pdf},
journal = {Science},
number = {6197},
pages = {668--673},
publisher = {American Association for the Advancement of Science},
title = {{A million spiking-neuron integrated circuit with a scalable communication network and interface}},
volume = {345},
year = {2014}
}
@article{Marber2004,
author = {Marber, Peter},
title = {{Globalization and Its Contents}},
year = {2004}
}
@inproceedings{Chen2010,
abstract = {Influence maximization, defined by Kempe, Kleinberg, and Tardos (2003), is the problem of finding a small set of seed nodes in a so- cial network that maximizes the spread of influence under certain influence cascade models. The scalability of influence maximiza- tion is a key factor for enabling prevalent viral marketing in large- scale online social networks. Prior solutions, such as the greedy al- gorithm of Kempe et al. (2003) and its improvements are slow and not scalable, while other heuristic algorithms do not provide con- sistently good performance on influence spreads. In this paper, we design a new heuristic algorithm that is easily scalable to millions of nodes and edges in our experiments. Our algorithm has a sim- ple tunable parameter for users to control the balance between the running time and the influence spread of the algorithm. Our results from extensive simulations on several real-world and synthetic net- works demonstrate that our algorithm is currently the best scalable solution to the influence maximization problem: (a) our algorithm scales beyond million-sized graphs where the greedy algorithm be- comes infeasible, and (b) in all size ranges, our algorithm performs consistently well in influence spread—it is always among the best algorithms, and in most cases it significantly outperforms all other scalable heuristics to as much as 100\%–260\% increase in influence spread.},
address = {New York, New York, USA},
author = {Chen, Wei and Wang, Chi and Wang, Yajun},
booktitle = {Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '10},
doi = {10.1145/1835804.1835934},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2010/Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '10/Chen, Wang, Wang/Chen, Wang, Wang\_2010\_Scalable influence maximization for prevalent viral marketing in large-scale social networks\_Proceedings of the 16.pdf:pdf},
isbn = {9781450300551},
keywords = {influence maximization,social networks,viral marketing},
pages = {1029},
publisher = {ACM Press},
title = {{Scalable influence maximization for prevalent viral marketing in large-scale social networks}},
url = {http://dl.acm.org/citation.cfm?doid=1835804.1835934},
year = {2010}
}
@article{Agarwal2012,
author = {Agarwal, Shankar and Abdalla, Filipe B. and Feldman, Hume a. and Lahav, Ofer and Thomas, Shaun a.},
doi = {10.1111/j.1365-2966.2012.21326.x},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/Monthly Notices of the Royal Astronomical Society/Agarwal et al/Agarwal et al.\_2012\_PkANN - I. Non-linear matter power spectrum interpolation through artificial neural networks\_Monthly Notices of the.pdf:pdf},
issn = {00358711},
journal = {Monthly Notices of the Royal Astronomical Society},
keywords = {2010,and the baryon oscilla-,cosmological parameters,cosmology,energy survey collaboration 2005,ivezic et al,large-scale,lsst,methods,numerical,structure of universe,telescope,the large synoptic survey,theory},
month = aug,
number = {2},
pages = {1409--1418},
title = {{PkANN - I. Non-linear matter power spectrum interpolation through artificial neural networks}},
url = {http://doi.wiley.com/10.1111/j.1365-2966.2012.21326.x},
volume = {424},
year = {2012}
}
@article{zhong2013medusa,
author = {Zhong, Jianlong and He, Bingsheng},
title = {{Medusa: A Parallel Graph Processing System on Graphics Processors}},
year = {2013}
}
@misc{Guerra2009,
abstract = {The integration of usable and flexible analysis support in modelling environments is a key success factor in Model-Driven Development. In this paradigm, models are the core asset from which code is automatically generated, and thus ensuring model correctness is a fundamental quality control activity. For this purpose, a common approach is to transform the system models into formal semantic domains for verification. However, if the analysis results are not shown in a proper way to the end-user (e.g. in terms of the original language) they may become useless. In this paper we present a novel DSVL called BaVeL that facilitates the flexible annotation of verification results obtained in semantic domains to different formats, including the context of the original language. BaVeL is used in combination with a consistency framework, providing support for all steps in a verification process: acquisition of additional input data, transformation of the system models into semantic domains, verification, and flexible annotation of analysis results. The approach has been validated analytically by the cognitive dimensions framework, and empirically by its implementation and application to several DSVLs. Here we present a case study of a notation in the area of Digital Libraries, where the analysis is performed by transformations into Petri nets and a process algebra. © 2008 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0402594v3},
author = {Guerra, Esther and de Lara, Juan and Malizia, Alessio and D\'{\i}az, Paloma},
booktitle = {Information and Software Technology},
doi = {10.1016/j.infsof.2008.09.005},
eprint = {0402594v3},
isbn = {0950-5849},
issn = {09505849},
keywords = {Back-annotation,Consistency,Domain-specific visual languages,Formal methods,Model transformation,Modelling environments},
pages = {769--784},
primaryClass = {arXiv:cond-mat},
title = {{Supporting user-oriented analysis for multi-view domain-specific visual languages}},
volume = {51},
year = {2009}
}
@misc{Kleiberg2005,
author = {Kleiberg, John and Tardos, \'{E}va},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2005/Unknown/Kleiberg, Tardos/Kleiberg, Tardos\_2005\_Algorithm Design\_Unknown.pdf:pdf},
pages = {864},
title = {{Algorithm Design}},
url = {http://www.google.com/patents/US2709584},
volume = {1},
year = {2005}
}
@article{Schmidh\uber2014,
abstract = {In recent years, deep neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
archivePrefix = {arXiv},
arxivId = {1404.7828},
author = {Schmidh\{$\backslash$"u\}ber, Juergen},
doi = {10.1016/j.neunet.2014.09.003},
eprint = {1404.7828},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/arXiv preprint arXiv \ldots/Schmidh\{u\}ber/Schmidh\{u\}ber\_2014\_Deep Learning in Neural Networks An Overview\_arXiv preprint arXiv \ldots.pdf:pdf},
issn = {18792782},
journal = {arXiv preprint arXiv: \ldots},
pages = {66},
title = {{Deep Learning in Neural Networks: An Overview}},
url = {http://arxiv.org/abs/1404.7828},
volume = {abs/1404.7},
year = {2014}
}
@article{Weihl1993,
abstract = {Specifications are at the core of modern modular programming methods for sequential as well as concurrent and distributed systems. In this chapter, we discuss the issues involved in writing specifications for concurrent and distributed systems. We present a simple method based on state machines and atomic actions, and show a number of examples of illustrating the use of the method. We discuss techniques that can be used to prove the correctness of an implementation of a module; these techniques can be used quite rigorously, or as the basis of more informal reasoning about correctness. We include a number of hints for writing good specifications.},
author = {Haller, P and Odersky, M},
isbn = {0201624273},
journal = {Coordination Models and Languages},
pages = {27--53},
title = {{Actors that unify threads and events}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-72794-1\_10},
year = {2007}
}
@article{Besta2014a,
author = {Besta, Maciej},
doi = {10.1109/SC.2014.34},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/Unknown/Besta/Besta\_2014\_Slim Fly A Cost Effective Low-Diameter Network Topology\_Unknown.pdf:pdf},
isbn = {9781479955008},
title = {{Slim Fly : A Cost Effective Low-Diameter Network Topology}},
year = {2014}
}
@article{Lim2013,
author = {Lim, Gino J. and Ma, Likang},
doi = {10.1016/j.cie.2012.10.008},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2013/Computers \& Industrial Engineering/Lim, Ma/Lim, Ma\_2013\_GPU-based parallel vertex substitution algorithm for the p-median problem\_Computers \& Industrial Engineering.pdf:pdf},
issn = {03608352},
journal = {Computers \& Industrial Engineering},
month = jan,
number = {1},
pages = {381--388},
publisher = {Elsevier Ltd},
title = {{GPU-based parallel vertex substitution algorithm for the p-median problem}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0360835212002707},
volume = {64},
year = {2013}
}
@article{Moore,
author = {Moore, JS and Byers, SE},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/Unknown/rwahlers.iweb.bsu.edu/Moore, Byers/Moore, Byers\_Unknown\_Using Pattern Recognition to Identify Academically 'At-Risk'Undergraduate Business Students\_rwahlers.iweb.bsu.edu.pdf:pdf},
journal = {rwahlers.iweb.bsu.edu},
title = {{Using Pattern Recognition to Identify Academically 'At-Risk'Undergraduate Business Students}},
url = {http://rwahlers.iweb.bsu.edu/abd2011/submissions in PDF/p11\_moore\_byers.pdf}
}
@incollection{Fournet2000,
author = {Fournet, C\'{e}dric and L\'{e}vy, Jean-Jacqes and Schmitt, Alan},
booktitle = {Theoretical Computer Science: Exploring New Frontiers of Theoretical Informatics},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2000/Theoretical Computer Science Exploring New Frontiers of Theoretical Informatics/Fournet, L\'{e}vy, Schmitt/Fournet, L\'{e}vy, Schmitt\_2000\_An Asynchronous, Distributed Implementation of Mobile Ambients\_Theoretical Computer Science Exploring New F.pdf:pdf},
keywords = {Short Version},
mendeley-tags = {Short Version},
pages = {348--364},
title = {{An Asynchronous, Distributed Implementation of Mobile Ambients}},
url = {http://pdf.aminer.org/000/233/596/reflecting\_mobile\_ambients\_into\_the\_p\_calculus.pdf},
year = {2000}
}
@article{Agha1985,
author = {Agha, GA},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/1985/Unknown/Agha/Agha\_1985\_Actors a model of concurrent computation in distributed systems\_Unknown.pdf:pdf},
institution = {MIT},
title = {{Actors: a model of concurrent computation in distributed systems}},
url = {http://dspace.mit.edu/handle/1721.1/6952},
year = {1985}
}
@inproceedings{Cassidy:2014:RSC:2683593.2683597,
address = {Piscataway, NJ, USA},
author = {Cassidy, Andrew S and Alvarez-Icaza, Rodrigo and Akopyan, Filipp and Sawada, Jun and Arthur, John V and Merolla, Paul A and Datta, Pallab and Tallada, Marc Gonzalez and Taba, Brian and Andreopoulos, Alexander and Amir, Arnon and Esser, Steven K and Kusnitz, Jeff and Appuswamy, Rathinakumar and Haymes, Chuck and Brezzo, Bernard and Moussalli, Roger and Bellofatto, Ralph and Baks, Christian and Mastro, Michael and Schleupen, Kai and Cox, Charles E and Inoue, Ken and Millman, Steve and Imam, Nabil and McQuinn, Emmett and Nakamura, Yutaka Y and Vo, Ivan and Guo, Chen and Nguyen, Don and Lekuch, Scott and Asaad, Sameh and Friedman, Daniel and Jackson, Bryan L and Flickner, Myron D and Risk, William P and Manohar, Rajit and Modha, Dharmendra S},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
doi = {10.1109/SC.2014.8},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis/Cassidy et al/Cassidy et al.\_2014\_Real-time Scalable Cortical Computing at 46 Giga-synaptic OPSWatt with \~{}100\&Times Speedup in Time-to-solution and \~{}1.pdf:pdf},
isbn = {978-1-4799-5500-8},
pages = {27--38},
publisher = {IEEE Press},
series = {SC '14},
title = {{Real-time Scalable Cortical Computing at 46 Giga-synaptic OPS/Watt with \~{}100\&Times; Speedup in Time-to-solution and \~{}100,000\&Times; Reduction in Energy-to-solution}},
url = {http://dx.doi.org/10.1109/SC.2014.8},
year = {2014}
}
@misc{TheMendeleySupportTeam2011b,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/Mendeley Desktop/The Mendeley Support Team/The Mendeley Support Team\_2011\_Getting Started with Mendeley\_Mendeley Desktop.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{Rintala2011,
abstract = {ABSTRACT Building upon findings of the ATTRACT (Enhance the Attractiveness of Studies in Science and Technology) project, this paper discusses some of the key aspects related to student retention in higher engineering and technology education. Student retention is an increasing concern in many institutions of higher education. The difficulty with international comparison, however, often lies in the differences between national systems, concepts and performance indicators. Findings of the ATTRACT project demonstrate that student attrition is a problem especially in engineering and technology education and among first-year students. In addition, male students tend to drop out of higher education generally more often than female students. Although several theories have been developed to explain the dropout phenomenon, the dominant theory is Tinto’s Student Integration Model [1], which emphasises the importance of social and academic integration of students in the prediction of student retention. However, educational persistence is above all a product of a complex set of interactions among personal, institutional and external factors. In order to prevent student attrition, the institutions need to take proactive steps to build personal relationships with their students and to identify already those students potentially at risk of dropping out.},
author = {Rintala, Ulla and Andersson, S and Kairamo, AK},
booktitle = {World Engineering Education Flash Week},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/World Engineering Education Flash Week/Rintala, Andersson, Kairamo/Rintala, Andersson, Kairamo\_2011\_How to retain students in higher engineering education Findings of the ATTRACT project\_World Engineerin.pdf:pdf},
keywords = {2,academic integration,definitions and indicators of,engineering education,first year experience,student retention,theories of dropout},
title = {{How to retain students in higher engineering education? Findings of the ATTRACT project}},
url = {http://www.attractproject.org/sites/default/files/document/ATTRACT\_WP8\_article\_SEFI\_Lisbon\_2011.pdf},
year = {2011}
}
@inproceedings{Lin2014,
abstract = {We observe that fence instructions used by programmers are usually only intended to order memory accesses within a limited scope. Based on this observation, we propose the concept fence scope which defines the scope within which a fence enforces the order of memory accesses, called scoped fence (S-Fence). S-Fence is a customizable fence, which enables programmers to express ordering demands by specifying the scope of fences when they only want to order part of memory accesses. At runtime, hardware uses the scope information conveyed by programmers to execute fence instructions in a manner that imposes fewer memory ordering constraints than a traditional fence, and hence improves program performance. Our experimental results show that the benefit of S-Fence hinges on the characteristics of applications and hardware parameters. A group of lock-free algorithms achieve peak speedups ranging from 1.13x to 1.34x; while full applications achieve speedups ranging from 1.04x to 1.23x.},
author = {Lin, Changhui and Nagarajan, Vijay and Gupta, Rajiv},
booktitle = {SC14: International Conference for High Performance Computing, Networking, Storage and Analysis},
doi = {10.1109/SC.2014.14},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/SC14 International Conference for High Performance Computing, Networking, Storage and Analysis/Lin, Nagarajan, Gupta/Lin, Nagarajan, Gupta\_2014\_Fence Scoping\_SC14 International Conference for High Performance Computing, Networking, Storage and Analysis.pdf:pdf},
isbn = {978-1-4799-5500-8},
keywords = {10,and,avoid these problems by,eschewing mutual exclusion,fence instructions,for example,improve scalability and robustness,is a popular,memory models,non-blocking work-stealing,scope,while still ensuring safety},
pages = {105--116},
title = {{Fence Scoping}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7012996},
year = {2014}
}
@article{Retention2011,
author = {Retention, Factors Predicting First-to-second-year},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/Unknown/Retention/Retention\_2011\_PREDICTORS OF RETENTION AND PROGRESSION TOWARD GRADUATION Part 2 Factors Predicting First-to-Second-Year Retention and P.pdf:pdf},
number = {December},
pages = {1--8},
title = {{PREDICTORS OF RETENTION AND PROGRESSION TOWARD GRADUATION Part 2 : Factors Predicting First-to-Second-Year Retention and Progression to Sophomore Status for the 2010 Cohort}},
year = {2011}
}
@article{Even-Dar2011b,
abstract = {We consider the spread maximization problem that was defined by Domingos and Richardson (2001, 2002) [7,22]. In this problem, we are given a social network represented as a graph and are required to find the set of the most "influential" individuals that by introducing them with a new technology, we maximize the expected number of individuals in the network, later in time, that adopt the new technology. This problem has applications in viral marketing, where a company may wish to spread the rumor of a new product via the most influential individuals in popular social networks such as Myspace and Blogsphere. The spread maximization problem was recently studied in several models of social networks (Kempe et al. (2003, 2005) [14,15], Mossel and Roch (2007) [20]). In this short paper we study this problem in the context of the well studied probabilistic voter model. We provide very simple and efficient algorithms for solving this problem. An interesting special case of our result is that the most natural heuristic solution, which picks the nodes in the network with the highest degree, is indeed the optimal solution. ?? 2010 Elsevier B.V. All rights reserved.},
author = {Even-Dar, Eyal and Shapira, Asaf},
doi = {10.1016/j.ipl.2010.11.015},
isbn = {3540771042},
issn = {00200190},
journal = {Information Processing Letters},
keywords = {Algorithms,Analysis of algorithms,Approximation algorithms,Social network,Spread maximization,Voter model},
pages = {184--187},
title = {{A note on maximizing the spread of influence in social networks}},
volume = {111},
year = {2011}
}
@article{Kwiatkowska2009,
author = {Kwiatkowska, Marta and Norman, Gethin and Parker, David and Vigliotti, Maria Grazia},
doi = {10.1016/j.tcs.2008.12.058},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2009/Theoretical Computer Science/Kwiatkowska et al/Kwiatkowska et al.\_2009\_Probabilistic Mobile Ambients\_Theoretical Computer Science.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = mar,
number = {12-13},
pages = {1272--1303},
title = {{Probabilistic Mobile Ambients}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397509000140},
volume = {410},
year = {2009}
}
@article{Leskovec2007,
address = {New York, New York, USA},
author = {Leskovec, Jure and Krause, Andreas and Guestrin, Carlos and Faloutsos, Christos and VanBriesen, Jeanne and Glance, Natalie},
doi = {10.1145/1281192.1281239},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2007/Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '07/Leskovec et al/Leskovec et al.\_2007\_Cost-effective outbreak detection in networks\_Proceedings of the 13th ACM SIGKDD international conference on Knowle.pdf:pdf},
isbn = {9781595936097},
journal = {Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '07},
keywords = {blogs,each layer shows an,figure 1,graphs,information cascade,information cascades,sensor placement,spread of information between,submodular functions,tion,virus propaga-,we want},
pages = {420},
publisher = {ACM Press},
title = {{Cost-effective outbreak detection in networks}},
url = {http://portal.acm.org/citation.cfm?doid=1281192.1281239},
year = {2007}
}
@inproceedings{7013013,
abstract = {This paper demonstrates how ideas from generative programming and software synthesis can help support the development of bulk-synchronous distributed memory kernels. These ideas are realized in a new language called MSL, a C-like language that combines synthesis features with high level notations for array manipulation and bulk-synchronous parallelism to simplify the semantic analysis required for synthesis. The paper shows that by leveraging these high level notations, it is possible to scale the synthesis and automated bug-finding technologies that underlie MSL to realistic computational kernels. Specifically, we demonstrate the methodology through case studies implementing non-trivial distributed kernels -- both regular and irregular -- from the NAS parallel benchmarks. We show that our approach can automatically infer many challenging details from these benchmarks and can enable high level implementation ideas to be reused between similar kernels. We also demonstrate that these high level notations map easily to low level C code and show that the performance of this generated code matches that of handwritten Fortran.},
author = {Xu, Zhilei and Solar-lezama, Armando},
booktitle = {High Performance Computing, Networking, Storage and Analysis, SC14: International Conference for},
doi = {10.1109/SC.2014.31},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/High Performance Computing, Networking, Storage and Analysis, SC14 International Conference for/Xu, Solar-lezama/Xu, Solar-lezama\_2014\_MSL a Synthesis Enabled Language for Distributed Implementations\_High Performance Computing, Networking, Storage.pdf:pdf},
isbn = {978-1-4799-5499-5},
pages = {311--322},
title = {{MSL : a Synthesis Enabled Language for Distributed Implementations}},
year = {2014}
}
@article{HaganM.T.1994,
abstract = {The Marquardt algorithm for nonlinear least squares is presented and is incorporated into the backpropagation algorithm for training feedforward neural networks. The algorithm is tested on several function approximation problems, and is compared with a conjugate gradient algorithm and a variable learning rate algorithm. It is found that the Marquardt algorithm is much more efficient than either of the other techniques when the network contains no more than a few hundred weightsThe Marquardt algorithm for nonlinear least squares is presented and is incorporated into the backpropagation algorithm for training feedforward neural networks. The algorithm is tested on several function approximation problems, and is compared with a conjugate gradient algorithm and a variable learning rate algorithm. It is found that the Marquardt algorithm is much more efficient than either of the other techniques when the network contains no more than a few hundred weights.},
author = {Hagen, Martin T. and Menhaj, Mohammad-B Bagher},
doi = {10.1109/72.329697},
journal = {IEEE Transactions on Neural Networks},
number = {6},
pages = {989--993},
title = {{Training feedforward networks with the Marquardt algorithm}},
volume = {5},
year = {1994}
}
@techreport{Nichol2013,
address = {Washington DC},
author = {Nichol, Jim},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2013/Unknown/Nichol/Nichol\_2013\_Russian Political , Economic , and Security Issues and U . S . Interests\_Unknown.pdf:pdf},
institution = {Congressional Research Service},
title = {{Russian Political , Economic , and Security Issues and U . S . Interests}},
year = {2013}
}
@article{Mount2010,
author = {Mount, David M},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2010/Unknown/Mount/Mount\_2010\_ANN Programming Manual\_Unknown.pdf:pdf},
title = {{ANN Programming Manual}},
year = {2010}
}
@article{Jaina,
annote = {The paper demonstrates how different routing and network connection protocol is extremely linked to the application. Also, the authors show scaling (using a simulation of a Cray explosion).},
author = {Jain, Nikhil and Bhatele, Abhinav and Ni, Xiang and Wright, Nicholas J and Kale, Laxmikant V},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/Unknown/Unknown/Jain et al/Jain et al.\_Unknown\_Maximizing Throughput on a Dragonfly Network\_Unknown.pdf:pdf},
isbn = {9781479955008},
keywords = {dragonfly networks,job place-,modeling,prediction},
title = {{Maximizing Throughput on a Dragonfly Network}}
}
@article{Blanchard2014,
author = {Blanchard, JD and Tanner, Jared},
doi = {10.1002/nla.1948},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2013/Mathematical Programming Computation/Blanchard, Tanner/Blanchard, Tanner\_2013\_GPU accelerated greedy algorithms for compressed sensing\_Mathematical Programming Computation.pdf:pdf},
issn = {10705325},
journal = {Mathematical Programming Computation},
keywords = {compressed sensing,gpu computing,greedy algorithm,hard thresholding,sparse},
month = jul,
pages = {n/a--n/a},
title = {{GPU accelerated greedy algorithms for compressed sensing}},
url = {http://doi.wiley.com/10.1002/nla.1948 http://link.springer.com/article/10.1007/s12532-013-0056-5},
year = {2013}
}
@article{Shewchuk1994,
author = {Shewchuk, Jonathan Richard},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/1994/Unknown/Shewchuk/Shewchuk\_1994\_An Introduction to the Conjugate Gradient Method Without the Agonizing Pain\_Unknown.pdf:pdf},
keywords = {1,2,5,agonizing pain,conjugate gradient method,convergence analysis,eigen do it if,eigenvalues,i try,jacobi iterations,preconditioning,thinking with eigenvectors and},
title = {{An Introduction to the Conjugate Gradient Method Without the Agonizing Pain}},
year = {1994}
}
@article{Chatterjee2014,
author = {Chatterjee, Niladrish and Connor, Mike O and Loh, Gabriel H and Jayasena, Nuwan and Balasubramonian, Rajeev},
doi = {10.1109/SC.2014.16},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/Unknown/Chatterjee et al/Chatterjee et al.\_2014\_Managing DRAM Latency Divergence in Irregular GPGPU Applications\_Unknown.pdf:pdf},
isbn = {9781479955008},
keywords = {GPU Memory Scheduling,aging dram latency divergence,in irregular},
mendeley-tags = {GPU Memory Scheduling},
title = {{Managing DRAM Latency Divergence in Irregular GPGPU Applications}},
year = {2014}
}
@article{Hewitt2010,
author = {Hewitt, Carl},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2010/arXiv preprint arXiv1008.1459/Hewitt/Hewitt\_2010\_Actor model of computation scalable robust information systems\_arXiv preprint arXiv1008.1459.pdf:pdf},
journal = {arXiv preprint arXiv:1008.1459},
pages = {1--60},
title = {{Actor model of computation: scalable robust information systems}},
url = {http://arxiv.org/abs/1008.1459},
year = {2010}
}
@article{Roos2012,
abstract = {This study was undertaken by David Roos, a USU doctoral student and an employee at Dixie State College, in fall semester 2009. The purpose of the study was to measure the possible impact that nonacademic student information would have on retention when used by advisors and shared in an advising session with students. This information was gathered using an in-class survey that identified nonacademic or “noncognitive” risk factors not apparent by looking at a high school transcript or reviewing a student’s demographic background. Such factors as college commitment, self-efficacy, and resiliency were measured using a survey instrument called the Student Strengths Inventory (SSI). With the assistance of course instructors, the 48-question survey was administered to 1,054 students enrolled in the college’s First Year Experience (FYE) course during the first week of October 2009. The results were tabulated and individual “student strengths profiles” were made available to students. These profiles showed each individual student his/her strengths and weaknesses relative to the likelihood of staying enrolled and persisting to graduation. The researcher thought that student retention could be increased by making the survey results available to advisors and asking them to utilize this information to help students develop an individualized action plan to address the areas of concern. To test this hypothesis, 200 students were randomly selected to either participate in a general advising session or a more targeted advising session where the survey results were discussed and an action plan created. In fall semester 2010, the retention rates were calculated and the students in the targeted advising sample group did, in fact, reenroll at a higher rate (49\% vs. 43\%), although this vi difference was not statistically significant. On the other hand, an important, statistically significant finding was that first-generation students were retained at a much higher rate (62\%) within the targeted advising group than first-generation students who did not receive targeted advising. Although additional research is needed, the possible benefit for individual students and for colleges and universities is that targeted advising represents a powerful tool for advisors and others to assist first-generation students, a group who are at greater risk of dropping out than the overall freshmen population.},
author = {Roos, RD},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/Unknown/Roos/Roos\_2012\_Relationship Between First-Year Student Retention, Noncognitive Risk Factors, and Student Advising\_Unknown.pdf:pdf},
title = {{Relationship Between First-Year Student Retention, Noncognitive Risk Factors, and Student Advising}},
url = {http://digitalcommons.usu.edu/etd/1167/},
year = {2012}
}
@article{Yu2014,
abstract = {Strategies to improve the visible resilience of applications require the ability to distinguish vulnerability difference across application components and selectively apply protection. Hence, quantitatively modeling application vulnerability, as a method to capture vulnerability variance within the application, is critical to evaluate and improve system resilience. The tradition methods cannot effectively quantify vulnerability, because they lack a holistic view to examine system resilience, and come with prohibitive evaluation costs. In this paper, we introduce a data-driven methodology to analyze application vulnerability based on a novel resilience metric, the data vulnerability factor (DVF). DVF integrates both application and specific hardware into the resilience analysis. To calculate DVF, we extend a performance modeling language to provide a fast modeling solution. Furthermore, we measure six representative computational kernels; we demonstrate the values of DVF by quantifying the impact of algorithm optimization on vulnerability and by quantifying the effectiveness of a hardware protection mechanism.},
author = {Yu, Li and Li, Dong and Mittal, Sparsh and Vetter, Jeffrey S},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/ACMIEEE International Conference for High Performance Computing, Networking, Storage, and Analysis (SC)/Yu et al/Yu et al.\_2014\_Quantitatively Modeling Application Resiliency with the Data Vulnerability Factor\_ACMIEEE International Conference for Hi.pdf:pdf},
isbn = {9781479955008},
journal = {ACM/IEEE International Conference for High Performance Computing, Networking, Storage, and Analysis (SC)},
keywords = {resilience},
title = {{Quantitatively Modeling Application Resiliency with the Data Vulnerability Factor}},
year = {2014}
}
@article{Heinecke2011,
author = {Heinecke, Alexander and Breuer, Alexander and Rettenberger, Sebastian and Bader, Michael and Gabriel, Alice-agnes and Pelties, Christian and Bode, Arndt and Barth, William and Liao, Xiang-ke},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/Unknown/Heinecke et al/Heinecke et al.\_2011\_Petascale High Order Dynamic Rupture Earthquake Simulations on Heterogeneous Supercomputers\_Unknown.pdf:pdf},
isbn = {9781479955008},
keywords = {ader-dg,dy-,earthquake simulation,erogeneous supercomputers,het-,hybrid parallelization,namic rupture,petascale performance,seissol},
title = {{Petascale High Order Dynamic Rupture Earthquake Simulations on Heterogeneous Supercomputers}},
year = {2011}
}
@article{Rosenblatt1958,
author = {Rosenblatt, F.},
doi = {10.1037/h0042519},
issn = {0033-295X},
journal = {Psychological Review},
keywords = {Perception},
month = nov,
number = {6},
pages = {386--408},
pmid = {13602029},
title = {{The perceptron: A probabilistic model for information storage and organization in the brain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/13602029},
volume = {65},
year = {1958}
}
@inproceedings{Jung2012,
abstract = {Influence maximization is the problem of selecting top k seed nodes in a social network to maximize their influence coverage under certain influence diffusion models. In this paper, we propose a novel algorithm IRIE that integrates the advantages of influence ranking (IR) and influence estimation (IE) methods for influence maximization in both the independent cascade (IC) model and its extension IC-N that incorporates negative opinion propagations. Through extensive experiments, we demonstrate that IRIE matches the influence coverage of other algorithms while scales much better than all other algorithms: it runs up to two orders of magnitude faster than the state-of-the-art algorithms such as PMIA for large networks with tens of millions of nodes and edges, while using only a fraction of memory comparing with PMIA.},
archivePrefix = {arXiv},
arxivId = {1111.4795v1},
author = {Jung, Kyomin and Heo, Wooram and Chen, Wei},
booktitle = {Proceedings - IEEE International Conference on Data Mining, ICDM},
doi = {10.1109/ICDM.2012.79},
eprint = {1111.4795v1},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/Proceedings - IEEE International Conference on Data Mining, ICDM/Jung, Heo, Chen/Jung, Heo, Chen\_2012\_IRIE Scalable and robust influence maximization in social networks\_Proceedings - IEEE International Conference on D.pdf:pdf},
isbn = {9780769549057},
issn = {15504786},
keywords = {Independent cascade model,Influence maximization,Social network analysis,Social network mining,Viral marketing},
pages = {918--923},
title = {{IRIE: Scalable and robust influence maximization in social networks}},
year = {2012}
}
@inproceedings{richardson2002mining,
author = {Richardson, Matthew and Domingos, Pedro},
booktitle = {Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining},
organization = {ACM},
pages = {61--70},
title = {{Mining knowledge-sharing sites for viral marketing}},
year = {2002}
}
@misc{TheMendeleySupportTeam2011a,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/Mendeley Desktop/The Mendeley Support Team/The Mendeley Support Team\_2011\_Getting Started with Mendeley\_Mendeley Desktop.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@misc{Roberts,
author = {Roberts, E},
title = {{Neural Networks - History}},
url = {http://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html},
urldate = {2014-08-15}
}
@article{Wang2010,
author = {Wang, Y and Cong, Gao and Song, Guojie and Xie, Kunquing},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2010/Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining/Wang et al/Wang et al.\_2010\_Community-based greedy algorithm for mining top-k influential nodes in mobile social networks.\_Proceedings of the 16th.pdf:pdf},
isbn = {9781450300551},
journal = {Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining},
keywords = {community detection,influence maximization,social networks},
pages = {1039--1048},
publisher = {ACM},
title = {{Community-based greedy algorithm for mining top-k influential nodes in mobile social networks.}},
url = {http://info.psu.edu.sa/psu/cis/mtounsi/~CS311/paper-10.pdf http://dl.acm.org/citation.cfm?id=1835935},
year = {2010}
}
@misc{Barooah,
author = {Barooah, Prabir},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/Unknown/Unknown/Barooah/Barooah\_Unknown\_Estimation on Graphs from Relative Measurements\_Unknown.pdf:pdf},
title = {{Estimation on Graphs from Relative Measurements}}
}
@article{Navarro2012,
author = {Navarro, S. G. and Corradi, R. L. M. and Mampaso, a.},
doi = {10.1051/0004-6361/201016422},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/Astronomy \& Astrophysics/Navarro, Corradi, Mampaso/Navarro, Corradi, Mampaso\_2012\_Automatic spectral classification of stellar spectra with low signal-to-noise ratio using artificial neur.pdf:pdf},
issn = {0004-6361},
journal = {Astronomy \& Astrophysics},
keywords = {astronomical databases,data analysis,general,methods,miscellaneous,planetary nebulae},
month = feb,
pages = {A76},
title = {{Automatic spectral classification of stellar spectra with low signal-to-noise ratio using artificial neural networks}},
url = {http://www.aanda.org/10.1051/0004-6361/201016422},
volume = {538},
year = {2012}
}
@inproceedings{Armstrong2014,
abstract = {Swift/T is a high-level language for writing concise, deterministic scripts that compose serial or parallel codes implemented in lower-level programming models into large-scale parallel applications. It executes using a data-driven task parallel execution model that is capable of orchestrating millions of concurrently executing asynchronous tasks on homogeneous or heterogeneous resources. Producing code that executes efficiently at this scale requires sophisticated compiler transformations: poorly optimized code inhibits scaling with excessive synchronization and communication. We present a comprehensive set of compiler techniques for data-driven task parallelism, including novel compiler optimizations and intermediate representations. We report application benchmark studies, including unbalanced tree search and simulated annealing, and demonstrate that our techniques greatly reduce communication overhead and enable extreme scalability, distributing up to 612 million dynamically load balanced tasks per second at scales of up to 262,144 cores without explicit parallelism, synchronization, or load balancing in application code.},
author = {Armstrong, Timothy G and Wozniak, Justin M and Wilde, Michael and Foster, Ian T},
booktitle = {SC14: International Conference for High Performance Computing, Networking, Storage and Analysis},
doi = {10.1109/SC.2014.30},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/SC14 International Conference for High Performance Computing, Networking, Storage and Analysis/Armstrong et al/Armstrong et al.\_2014\_Compiler Techniques for Massively Scalable Implicit Task Parallelism\_SC14 International Conference for High Perfor.pdf:pdf},
isbn = {978-1-4799-5500-8},
keywords = {Data models,Load modeling,Optimization,Parallel processing,Runtime,Servers,Synchronization},
pages = {299--310},
title = {{Compiler Techniques for Massively Scalable Implicit Task Parallelism}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7013012},
year = {2014}
}
@article{Inam2011,
author = {Inam, Rafia},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/\ldots University, M\"{a}lardalen Real-Time Research Centre/Inam/Inam\_2011\_An Introduction to GPGPU Programming - CUDA Architeture\_\ldots University, M\"{a}lardalen Real-Time Research Centre.pdf:pdf},
journal = {\ldots University, M\"{a}lardalen Real-Time Research Centre},
title = {{An Introduction to GPGPU Programming - CUDA Architeture}},
url = {http://www.idt.mdh.se/kurser/dva314/HT2012/HT2011/material/GPGPUProgrammingUsingCUDA.pdf},
year = {2011}
}
@article{Ghaderi2012,
author = {Ghaderi, K and Rostami, T and Karimi, A and Ghasema, S and Khodamoradi, S},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/Unknown/Ghaderi et al/Ghaderi et al.\_2012\_Application of a Probabilistic Neural Network in Radial Velocity Curve Analysis of the Spectroscopic Systems PT.pdf:pdf},
keywords = {binaries,eclipsing -- stars,spectroscopic,stars},
number = {2},
pages = {1718--1724},
title = {{Application of a Probabilistic Neural Network in Radial Velocity Curve Analysis of the Spectroscopic Systems PT Vel , MU Cas , V459 Cas ,  Ori Aa and  Cir A}},
volume = {2},
year = {2012}
}
@misc{Pnge,
abstract = {Scenarios for using Oracle Nashorn as a command-line tool and as an embedded interpreter in Java applications},
author = {Pange, Julian},
keywords = {JVM,Java,Java Magazine,JavaScript Engine,Julien Ponge,Oracle Nashorn},
title = {{Oracle Nashorn: A Next-Generation JavaScript Engine for the JVM}},
url = {http://www.oracle.com/technetwork/articles/java/jf14-nashorn-2126515.html},
urldate = {2014-12-04}
}
@article{Calvert2013,
abstract = {As modern architectures introduce additional heterogeneity and parallelism, we look for ways to deal with this that do not involve specialising software to every platform. In this paper, we take the Join Calculus, an elegant model for concurrent computation, and show how it can be mapped to an architecture by a Cartesian-product-style construction, thereby making use of the calculus’ inherent non-determinism to encode placement choices. This unifies the concepts of placement and scheduling into a single task.},
author = {Calvert, Peter and Mycroft, Alan},
doi = {10.4204/EPTCS.109.2},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2013/Electronic Proceedings in Theoretical Computer Science/Calvert, Mycroft/Calvert, Mycroft\_2013\_Mapping the Join Calculus to Heterogeneous Hardware\_Electronic Proceedings in Theoretical Computer Science.pdf:pdf},
issn = {2075-2180},
journal = {Electronic Proceedings in Theoretical Computer Science},
pages = {7--12},
title = {{Mapping the Join Calculus to Heterogeneous Hardware}},
url = {http://arxiv.org/abs/1302.6329v1},
volume = {109},
year = {2013}
}
@article{Preissl2012,
abstract = {Inspired by the function, power, and volume of the organic brain, we are developing TrueNorth, a novel modu- lar, non-von Neumann, ultra-low power, compact architecture. TrueNorth consists of a scalable network of neurosynaptic cores, with each core containing neurons, dendrites, synapses, and axons. To set sail for TrueNorth, we developed Compass, a multi-threaded, massively parallel functional simulator and a parallel compiler that maps a network of long-distance pathways in the macaque monkey brain to TrueNorth. We demonstrate near-perfect weak scaling on a 16 rack IBM® Blue Gene®/Q (262144 CPUs, 256 TB memory), achieving an unprecedented scale of 256 million neurosynaptic cores containing 65 billion neurons and 16 trillion synapses running only 388× slower than real time with an average spiking rate of 8.1 Hz. By using emerging PGAS communication primitives, we also demonstrate 2× better real-time performance over MPI primitives on a 4 rack Blue Gene/P (16384 CPUs, 16 TB memory).},
annote = {Sims information},
author = {Preissl, Robert and Wong, Theodore M. and Datta, Pallab and Flickner, Myron and Singh, Raghavendra and Esser, Steven K. and Risk, William P. and Simon, Horst D. and Modha, Dharmendra S.},
doi = {10.1109/SC.2012.34},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/International Conference for High Performance Computing, Networking, Storage and Analysis, SC/Preissl et al/Preissl et al.\_2012\_Compass A scalable simulator for an architecture for cognitive computing\_International Conference for High Performan.pdf:pdf},
isbn = {9781467308069},
issn = {21674329},
journal = {International Conference for High Performance Computing, Networking, Storage and Analysis, SC},
title = {{Compass: A scalable simulator for an architecture for cognitive computing}},
year = {2012}
}
@misc{Long,
author = {Long, Lyle and {The Pennsylvania State University}},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/Unknown/Unknown/Long, The Pennsylvania State University/Long, The Pennsylvania State University\_Unknown\_Computational Science - Background\_Unknown.html:html},
title = {{Computational Science - Background}},
url = {http://www.csci.psu.edu/background.html},
urldate = {2013-07-01}
}
@article{Zhu2014,
abstract = {Information flows in a network where individuals influence each other. In this paper, we study the influence maximization problem of finding a small subset of nodes in a social network that could maximize the spread of influence. We propose a novel information diffusion model CTMC-ICM, which introduces the theory of Continuous-Time Markov Chain (CTMC) into the Independent Cascade Model (ICM). Furthermore, we propose a new ranking metric named SpreadRank generalized by the new information propagation model CTMC-ICM. We experimentally demonstrate the new ranking method that can, in general, extract nontrivial nodes as an influential node set that maximizes the spread of information in a social network and is more efficient than a distance-based centrality. © 2014 Elsevier Inc. All rights reserved.},
author = {Zhu, Tian and Wang, Bai and Wu, Bin and Zhu, Chuanxi},
doi = {10.1016/j.ins.2014.03.070},
isbn = {1381187870},
issn = {00200255},
journal = {Information Sciences},
keywords = {Data mining,Influence maximization,Information propagation,Node centrality,Social network},
pages = {535--544},
title = {{Maximizing the spread of influence ranking in social networks}},
volume = {278},
year = {2014}
}
@article{Zhu2014a,
abstract = {Information flows in a network where individuals influence each other. In this paper, we study the influence maximization problem of finding a small subset of nodes in a social network that could maximize the spread of influence. We propose a novel information diffusion model CTMC-ICM, which introduces the theory of Continuous-Time Markov Chain (CTMC) into the Independent Cascade Model (ICM). Furthermore, we propose a new ranking metric named SpreadRank generalized by the new information propagation model CTMC-ICM. We experimentally demonstrate the new ranking method that can, in general, extract nontrivial nodes as an influential node set that maximizes the spread of information in a social network and is more efficient than a distance-based centrality. © 2014 Elsevier Inc. All rights reserved.},
author = {Zhu, Tian and Wang, Bai and Wu, Bin and Zhu, Chuanxi},
doi = {10.1016/j.ins.2014.03.070},
isbn = {1381187870},
issn = {00200255},
journal = {Information Sciences},
keywords = {Data mining,Influence maximization,Information propagation,Node centrality,Social network},
pages = {535--544},
title = {{Maximizing the spread of influence ranking in social networks}},
volume = {278},
year = {2014}
}
@article{Jung2011,
archivePrefix = {arXiv},
arxivId = {1111.4795},
author = {Jung, Kyomin and Heo, Wooram and Chen, Wei},
eprint = {1111.4795},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/arXiv preprint arXiv1111.4795/Jung, Heo, Chen/Jung, Heo, Chen\_2011\_IRIE Scalable and Robust Influence Maximization in Social Networks\_arXiv preprint arXiv1111.4795.pdf:pdf},
journal = {arXiv preprint arXiv:1111.4795},
month = nov,
pages = {1--19},
title = {{IRIE: Scalable and Robust Influence Maximization in Social Networks}},
url = {http://arxiv.org/abs/1111.4795v3},
year = {2011}
}
@techreport{export:210931,
abstract = {<p>High-scale interactive services demand high throughput with low latency and
high availability, difficult goals to meet with the traditional stateless 3-tier
architecture. The actor model makes it natural to build a stateful middle tier
and achieve the required performance. However, the popular actor model platforms
still pass many distributed systems problems to the developers.

The Orleans programming model introduces the novel abstraction of virtual actors
that solves a number of the complex distributed systems problems, such as
reliability and distributed resource management, liberating the developers from
dealing with those concerns. At the same time, the Orleans runtime enables
applications to attain high performance, reliability and scalability.

This paper presents the design principles behind Orleans and demonstrates how
Orleans achieves a simple programming model that meets these goals. We describe
how Orleans simplified the development of several scalable production
applications on Windows Azure, and report on the performance of those production
systems.</p>},
author = {Bernstein, Philip A and Bykov, Sergey and Geller, Alan and Kliot, Gabriel and Thelin, Jorgen},
month = mar,
number = {MSR-TR-2014-41},
title = {{Orleans: Distributed Virtual Actors for Programmability and Scalability}},
url = {http://research.microsoft.com/apps/pubs/default.aspx?id=210931},
year = {2014}
}
@article{Phillips2013,
author = {Phillips, Jc and Sun, Yanhua and Jain, Nikhil and Bohm, Ej and Kal\'{e}, Lv},
doi = {10.1109/SC.2014.12},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2013/Charm.Cs.Illinois.Edu/Phillips et al/Phillips et al.\_2013\_Mapping to Irregular Torus Topologies and Other Techniques for Petascale Biomolecular Simulation\_Charm.Cs.Illinois..pdf:pdf},
isbn = {9781479955008},
journal = {Charm.Cs.Illinois.Edu},
title = {{Mapping to Irregular Torus Topologies and Other Techniques for Petascale Biomolecular Simulation}},
url = {http://charm.cs.illinois.edu/newPapers/14-23/paper.pdf},
year = {2013}
}
@article{Giridhar2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1203.2014v1},
author = {Giridhar, Sunetra and Goswami, Aruna and Kunder, Andrea and Muneer, S and Kumar, G Selva},
eprint = {arXiv:1203.2014v1},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/Unknown/Giridhar et al/Giridhar et al.\_2012\_arXiv 1203 . 2014v1 astro-ph . SR 9 Mar 2012 The Stellar parametrization using Artificial Neural Network\_Unknown.pdf:pdf},
keywords = {absolute magnitude,ann,stellar abundances},
number = {2010},
pages = {1--6},
title = {{arXiv : 1203 . 2014v1 [ astro-ph . SR ] 9 Mar 2012 The Stellar parametrization using Artificial Neural Network}},
volume = {00},
year = {2012}
}
@article{Fournet2002,
author = {Fournet, C and Gonthier, Georges},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2002/Applied Semantics/Fournet, Gonthier/Fournet, Gonthier\_2002\_The join calculus a language for distributed mobile programming\_Applied Semantics.pdf:pdf},
journal = {Applied Semantics},
number = {September 2000},
pages = {1--66},
title = {{The join calculus: a language for distributed mobile programming}},
url = {http://link.springer.com/chapter/10.1007/3-540-45699-6\_6},
year = {2002}
}
@article{Yuan2014a,
abstract = {Large scale graph processing represents an interesting challenge due to the lack of locality. This paper presents PathGraph for improving iterative graph computation on graphs with billions of edges. Our system design has three unique features: First, we model a large graph using a collection of tree-based partitions and use an path-centric computation rather than vertex-centric or edge-centric computation. Our parallel computation model significantly improves the memory and disk locality for performing iterative computation algorithms. Second, we design a compact storage that further maximize sequential access and minimize random access on storage media. Third, we implement the path-centric computation model by using a scatter/gather programming model, which parallels the iterative computation at partition tree level and performs sequential updates for vertices in each partition tree. The experimental results show that the path-centric approach outperforms vertexcentric and edge-centric systems on a number of graph algorithms for both in-memory and out-of-core graphs.},
author = {Yuan, Pingpeng and Zhang, Wenya and Xie, Changfeng and Jin, Hai and Liu, Ling and Lee, Kisung},
doi = {10.1109/SC.2014.38},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/SC14 International Conference for High Performance Computing, Networking, Storage and Analysis/Yuan et al/Yuan et al.\_2014\_Fast Iterative Graph Computation A Path Centric Approach\_SC14 International Conference for High Performance Computing,.pdf:pdf},
isbn = {9781479955008},
journal = {SC14: International Conference for High Performance Computing, Networking, Storage and Analysis},
keywords = {Lecture 13,computing,graph,iterative computation,path},
mendeley-tags = {Lecture 13},
title = {{Fast Iterative Graph Computation : A Path Centric Approach}},
year = {2014}
}
@inproceedings{Wongkhamdi2010,
abstract = {Predicting student graduation outcomes is critical for educational institutions because it allows them to develop strategic programs that will help to improve student performance and maintain student numbers during their period of study in an institution. In this article, we present the results of an experimental comparison study of Discriminant Analysis and Artificial Neural Network (ANN) for predicting student graduation outcomes. A sample of 594 student profiles were used to train and test our model. The power of the model can be measured by Classification correct rate (CCR). The average Classification correct rate for the ANN was higher than Classical Discriminant Analysis. The best efficiency was 93.3\% and analysis of classification was 81.5\%, respectively},
address = {Chonburi},
author = {Wongkhamdi, Thipsuda and Seresangtakul, Pusadee},
booktitle = {Proceedings of the Second International Conference on Knowledge and Smart Technologies},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2010/Proceedings of the Second International Conference on Knowledge and Smart Technologies/Wongkhamdi, Seresangtakul/Wongkhamdi, Seresangtakul\_2010\_A Comparison of Classical Discriminant Analysis and Artificial Neural Networks in Predicting Student Grad.pdf:pdf},
keywords = {Back-propagation,Discriminant Analysis,Forecasting,Neural Network,Prediction,Student Success},
pages = {29--34},
title = {{A Comparison of Classical Discriminant Analysis and Artificial Neural Networks in Predicting Student Graduation Outcomes}},
url = {http://kst.buu.ac.th/proceedings/KST2010/docs/en06.pdf},
volume = {2010},
year = {2010}
}
@article{Even-Dar2011,
abstract = {We consider the spread maximization problem that was defined by Domingos and Richardson (2001, 2002) [7,22]. In this problem, we are given a social network represented as a graph and are required to find the set of the most "influential" individuals that by introducing them with a new technology, we maximize the expected number of individuals in the network, later in time, that adopt the new technology. This problem has applications in viral marketing, where a company may wish to spread the rumor of a new product via the most influential individuals in popular social networks such as Myspace and Blogsphere. The spread maximization problem was recently studied in several models of social networks (Kempe et al. (2003, 2005) [14,15], Mossel and Roch (2007) [20]). In this short paper we study this problem in the context of the well studied probabilistic voter model. We provide very simple and efficient algorithms for solving this problem. An interesting special case of our result is that the most natural heuristic solution, which picks the nodes in the network with the highest degree, is indeed the optimal solution. ?? 2010 Elsevier B.V. All rights reserved.},
author = {Even-Dar, Eyal and Shapira, Asaf},
doi = {10.1016/j.ipl.2010.11.015},
isbn = {3540771042},
issn = {00200190},
journal = {Information Processing Letters},
keywords = {Algorithms,Analysis of algorithms,Approximation algorithms,Social network,Spread maximization,Voter model},
pages = {184--187},
title = {{A note on maximizing the spread of influence in social networks}},
volume = {111},
year = {2011}
}
@inproceedings{goyal2011celf++,
author = {Goyal, Amit and Lu, Wei and Lakshmanan, Laks V S},
booktitle = {Proceedings of the 20th international conference companion on World wide web},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/Proceedings of the 20th international conference companion on World wide web/Goyal, Lu, Lakshmanan/Goyal, Lu, Lakshmanan\_2011\_Celf optimizing the greedy algorithm for influence maximization in social networks\_Proceedings of the 20th in.pdf:pdf},
isbn = {9781450306379},
keywords = {celf,greedy algorithm,influence propagation,marketing,social networks,submodularity,viral},
organization = {ACM},
pages = {47--48},
title = {{Celf++: optimizing the greedy algorithm for influence maximization in social networks}},
year = {2011}
}
@article{Heybrock2014,
author = {Heybrock, Simon and Jo\'{o}, B\'{a}lint and Kalamkar, Dhiraj D and Smelyanskiy, Mikhail},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/Unknown/Heybrock et al/Heybrock et al.\_2014\_Lattice QCD with domain decomposition on Intel R Xeon Phi co-processors\_Unknown.pdf:pdf},
isbn = {9781479955008},
keywords = {domain decomposition,intel r xeon phi},
title = {{Lattice QCD with domain decomposition on Intel R Xeon Phi co-processors}},
year = {2014}
}
@article{Even-Dar2011a,
abstract = {We consider the spread maximization problem that was defined by Domingos and Richardson (2001, 2002) [7,22]. In this problem, we are given a social network represented as a graph and are required to find the set of the most "influential" individuals that by introducing them with a new technology, we maximize the expected number of individuals in the network, later in time, that adopt the new technology. This problem has applications in viral marketing, where a company may wish to spread the rumor of a new product via the most influential individuals in popular social networks such as Myspace and Blogsphere. The spread maximization problem was recently studied in several models of social networks (Kempe et al. (2003, 2005) [14,15], Mossel and Roch (2007) [20]). In this short paper we study this problem in the context of the well studied probabilistic voter model. We provide very simple and efficient algorithms for solving this problem. An interesting special case of our result is that the most natural heuristic solution, which picks the nodes in the network with the highest degree, is indeed the optimal solution. ?? 2010 Elsevier B.V. All rights reserved.},
author = {Even-Dar, Eyal and Shapira, Asaf},
doi = {10.1016/j.ipl.2010.11.015},
isbn = {3540771042},
issn = {00200190},
journal = {Information Processing Letters},
keywords = {Algorithms,Analysis of algorithms,Approximation algorithms,Social network,Spread maximization,Voter model},
pages = {184--187},
title = {{A note on maximizing the spread of influence in social networks}},
volume = {111},
year = {2011}
}
@inproceedings{Imbrie2008,
abstract = {Engineering students’ affective self-beliefs can be influential factors directly or indirectly affecting their academic success and career decision. This paper examines whether students’ non-cognitive factors can be used, alone or in combination with cognitive factors, in artificial neural network (ANN) models to predict engineering student’s future retention. Four ANN based retention prediction models using different combinations of non-cognitive and cognitive factors are presented. The independent variables includes survey items from nine non-cognitive constructs (leadership, deep learning, surface learning, teamwork, self-efficacy, motivation, meta-cognition, expectancy-value, and major decision) and eleven cognitive items representing student’s high school academic performance. The dependent variable (i.e., the output from these models) is the student’s retention status after one year. Data from more than 4900 first-year engineering students from three freshman cohorts (2004, 2005, 2006) in a large Midwestern university were collected and utilized in training and testing these ANN prediction models. Among the four ANN models developed, the model combining 11 cognitive items and 60 selected non-cognitive items has the highest overall prediction accuracy at 71.3\%, probability of detection (POD) for retained students at 78.7\% and POD for not retained student at 40.5\%. Removing the 11 cognitive items from this model, the overall prediction accuracy would drop slightly to 70.5\%. Results from training and testing the same model using student data from different cohorts indicate the ANN model’s predictive performance is generally stable across different cohort years. Also, a model trained with earlier year (2004) freshman cohort’s data has maintained its predictive power very well when tested with student data from later (2005 and 2006) cohorts.},
address = {Pittsburg, PA},
author = {Imbrie, P K and Lin, Joe Jien-jou and Malyscheff, Alexander},
booktitle = {2008 Annual Conference \& Exposition of the American Society for Engineering Education},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2008/2008 Annual Conference \& Exposition of the American Society for Engineering Education/Imbrie, Lin, Malyscheff/Imbrie, Lin, Malyscheff\_2008\_Artificial Intelligence Methods to Forecast Engineering Students’ Retention Based on Cognitive and Non-co.pdf:pdf},
organization = {American Society for Engineering Education},
title = {{Artificial Intelligence Methods to Forecast Engineering Students’ Retention Based on Cognitive and Non-cognitive Factors}},
url = {http://search.asee.org/search/click?query=session\_title:"Recruitment+and+Retention"+AND+conference:"2008+Annual+Conference+\&+Exposition"\&title=file://localhost/E:/search/conference/17/AC 2008Full2417.pdf\&url=/search/fetch?url=file\%3A\%2F\%2Flocalhost\%2FE\%3A\%2Fsearch\%2Fconference\%2F17\%2FAC\%25202008Full2417.pdf\&index=conference\_papers\&space=129746797203605791716676178\&type=application\%2Fpdf\&charset=\&spaceId=12974679720},
year = {2008}
}
@article{Heidari2015,
author = {Blanchard, JD and Tanner, J and Wei, K},
doi = {10.1016/j.physa.2014.10.088},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/Physica A Statistical Mechanics and its Applications/Blanchard, Tanner, Wei/Blanchard, Tanner, Wei\_2014\_Conjugate gradient iterative hard thresholding observed noise stability for compressed sensing\_Physica A Sta.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
month = feb,
pages = {124--133},
publisher = {Elsevier B.V.},
title = {{Conjugate gradient iterative hard thresholding: observed noise stability for compressed sensing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378437114009431 http://eprints.maths.ox.ac.uk/1806/},
volume = {420},
year = {2014}
}
@article{Georganasa,
author = {Georganas, Evangelos and Bulu\c{c}, A and Chapman, Jarrod},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/Unknown/Eecs.Berkeley.Edu/Georganas, Bulu\c{c}, Chapman/Georganas, Bulu\c{c}, Chapman\_Unknown\_Parallel De Bruijn Graph Construction and Traversal for De Novo Genome Assembly\_Eecs.Berkeley.Edu.pdf:pdf},
journal = {Eecs.Berkeley.Edu},
keywords = {Lecture 14},
mendeley-tags = {Lecture 14},
title = {{Parallel De Bruijn Graph Construction and Traversal for De Novo Genome Assembly}},
url = {http://www.eecs.berkeley.edu/~egeor/sc14\_genome.pdf}
}
@misc{Hasler2013,
author = {Hasler, Jennifer and Marr, Bo},
booktitle = {Frontiers in Neuroscience},
doi = {10.3389/fnins.2013.00118},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2013/Frontiers in Neuroscience/Hasler, Marr/Hasler, Marr\_2013\_Finding a roadmap to achieve large neuromorphic hardware systems\_Frontiers in Neuroscience.pdf:pdf},
issn = {1662453X},
keywords = {FPAA,Neuromorphic Computing,Neuromorphic engineering,Reconfigurable analog,Simulink},
mendeley-tags = {Neuromorphic Computing},
pmid = {24058330},
title = {{Finding a roadmap to achieve large neuromorphic hardware systems}},
year = {2013}
}
@inproceedings{Karamouzis2008,
abstract = {Declining student graduation rates is a significant and growing problem in higher education. Students are dropping out from colleges for a variety of reasons Abstract— Declining student graduation rates is a significant and school administrators are scrambling to increase graduation rates. Predicting student graduation is of great value to schools and an enormous potential utility for targeted intervention. Considering the promising behavior of Artificial Neural Networks (ANNs) as classifiers led us into the development, training, and testing of an ANN for predicting student graduation outcomes. The network was developed as a three-layered perceptron and was trained using the backpropagation principles. For training and testing various experiments were executed. In these experiments, a sample of 1,407 profiles of students was used. The sample represented students at Waubonsee College and it was divided into two sets. The first set of 1,100 profiles was used for training and the remaining 307 profiles were used for testing. The average predictability rate for the training and test sets were 77\% and 68\%, respectively.},
address = {San Francisco},
author = {Karamouzis, Stamos T and Vrettos, Andreas},
booktitle = {Proceedings of the World Congress on Engineering and Computer Science},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2008/Proceedings of the World Congress on Engineering and Computer Science/Karamouzis, Vrettos/Karamouzis, Vrettos\_2008\_An Artificial Neural Network for Predicting Student Graduation Outcomes\_Proceedings of the World Congress on En.pdf:pdf},
isbn = {9789889867102},
keywords = {Forecasting,Prediction,Retention,Student Success},
mendeley-tags = {Forecasting,Prediction,Retention,Student Success},
pages = {22--25},
title = {{An Artificial Neural Network for Predicting Student Graduation Outcomes}},
year = {2008}
}
@inproceedings{Sridharan2014a,
address = {New Orleans},
author = {Sridharan, Srinivas and Dinan, James and Kalamkar, Dhiraj D},
booktitle = {SC14: International Conference for High Performance Computing, Networking, Storage and Analysis},
doi = {10.1109/SC.2014.45},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/SC14 International Conference for High Performance Computing, Networking, Storage and Analysis/Sridharan, Dinan, Kalamkar/Sridharan, Dinan, Kalamkar\_2014\_Enabling Efficient Multithreaded MPI Communication Through a Library-Based Implementation of MPI Endpoin.pdf:pdf},
isbn = {9781479955008},
keywords = {endpoints,hybrid parallel programming,mpi},
pages = {487--498},
title = {{Enabling Efficient Multithreaded MPI Communication Through a Library-Based Implementation of MPI Endpoints}},
year = {2014}
}
@inproceedings{Bohra2011,
abstract = {Many problems arising in the study of computer science are well modeled by mathematical graphs. We use the term ―(n, m)–graph‖ to denote a graph on n vertices with m edges. One use of graph theory is to address specific important network reliability problems. These problems are translated easily into problems of optimizing a selected measure on an (n, m)–graph. The most common optimization problems specify both the edge count and vertex count of the graph. There are several open graph optimization problems that are not yet susceptible to theoretical analysis, which is the preferred way to approach such problems. This project describes the use of genetic algorithms to generate a large number of candidate graphs which can then be assessed for optimality under any computable measure. The goal of this project is to suggest certain candidate graphs for further theoretical analysis. In the genetic algorithm approach, each of a set of candidate solutions is assessed for optimality. Some of these candidates are retained and new candidate solutions are generated using pseudo–random methods. When applied to graph optimality problems, we thought it best to work with the adjacency matrix representation of the graph. The first part of this paper describes the approach to storing the adjacency matrix of a simple graph, which can be either directed or undirected. We then focus on undirected graphs and present a data structure that guarantees that any graph produced by the genetic operators will remain a valid (n, m)–graph.},
author = {Bohra, Himanshu and Hearn, Patrick and Hodges, Richard and Plagge, Mark and Short, Brandon},
booktitle = {Proceedings of the 2011 Mid-Southeast Chapter of the ACM},
pages = {26},
title = {{Genetic Algorithms for Assesing Graph Optimality}},
url = {http://www.acmmidsoutheast.org/related-links/documents/2011\_Proceedings.pdf?attredirects=0\&d=1},
year = {2011}
}
@article{Blanchard2014a,
author = {Blanchard, Jeffrey D and Tanner, Jared and Wei, Ke},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/Unknown/Blanchard, Tanner, Wei/Blanchard, Tanner, Wei\_2014\_Conjugate Gradient Iterative Hard Thresholding Observed Noise Stability for Compressed Sensing\_Unknown.pdf:pdf},
number = {May},
title = {{Conjugate Gradient Iterative Hard Thresholding : Observed Noise Stability for Compressed Sensing}},
year = {2014}
}
@article{Mirzasoleiman2013,
abstract = {Many large-scale machine learning problems (such as clustering, non-parametric learning, kernel machines, etc.) require selecting, out of a massive data set, a manageable, representative subset. Such problems can often be reduced to maximizing a submodular set function subject to cardinality constraints. Classical approaches require centralized access to the full data set; but for truly large-scale problems, rendering the data centrally is often impractical. In this paper, we consider the problem of submodular function maximization in a distributed fashion. We develop a simple, two-stage protocol GreeDI, that is easily implemented using MapReduce style computations. We theoretically analyze our approach, and show, that under certain natural conditions, performance close to the (impractical) centralized approach can be achieved. In our extensive experiments, we demonstrate the effectiveness of our approach on several applications, including sparse Gaussian process inference on tens of millions of examples using Hadoop.},
author = {Inam, R},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/\ldots University, M\"{a}lardalen Real-Time Research Centre/Inam/Inam\_2011\_An Introduction to GPGPU Programming-CUDA Architecture\_\ldots University, M\"{a}lardalen Real-Time Research Centre.pdf:pdf},
journal = {\ldots University, M\"{a}lardalen Real-Time Research Centre},
pages = {1--9},
title = {{An Introduction to GPGPU Programming-CUDA Architecture}},
url = {http://papers.nips.cc/paper/5039-distributed-submodular-maximization-identifying-representative-elements-in-massive-data http://www.idt.mdh.se/kurser/dva314/HT2012/HT2011/material/GPGPUProgrammingUsingCUDA.pdf},
year = {2011}
}
@inproceedings{Barker2004,
author = {Barker, K and Trafalis, T. and Rhoads, T.R.},
booktitle = {Systems and Information Engineering Design Symposium, 2004. Proceedings of the 2004 IEEE},
doi = {doi: 10.1109/SIEDS.2004.239819},
pages = {79--86},
title = {{Learning from Student Data}},
url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=\&arnumber=1314666\&isnumber=29144},
year = {2004}
}
@misc{TheMendeleySupportTeam2011c,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/Mendeley Desktop/The Mendeley Support Team/The Mendeley Support Team\_2011\_Getting Started with Mendeley\_Mendeley Desktop.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Thai2012,
author = {Thai, Le Hoang and Hai, Tran Son and Thuy, Nguyen Thanh},
doi = {10.5815/ijitcs.2012.05.05},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/International Journal of Information Technology and Computer Science/Thai, Hai, Thuy/Thai, Hai, Thuy\_2012\_Image Classification using Support Vector Machine and Artificial Neural Network\_International Journal of Informatio.pdf:pdf},
issn = {20749007},
journal = {International Journal of Information Technology and Computer Science},
month = may,
number = {5},
pages = {32--38},
title = {{Image Classification using Support Vector Machine and Artificial Neural Network}},
url = {http://www.mecs-press.org/ijitcs/ijitcs-v4-n5/v4n5-5.html},
volume = {4},
year = {2012}
}
@inproceedings{Hewitt:1973:UMA:1624775.1624804,
address = {San Francisco, CA, USA},
author = {Hewitt, Carl and Bishop, Peter and Steiger, Richard},
booktitle = {Proceedings of the 3rd International Joint Conference on Artificial Intelligence},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/1973/Proceedings of the 3rd International Joint Conference on Artificial Intelligence/Hewitt, Bishop, Steiger/Hewitt, Bishop, Steiger\_1973\_A Universal Modular ACTOR Formalism for Artificial Intelligence\_Proceedings of the 3rd International Joint.pdf:pdf},
pages = {235--245},
publisher = {Morgan Kaufmann Publishers Inc.},
series = {IJCAI'73},
title = {{A Universal Modular ACTOR Formalism for Artificial Intelligence}},
url = {http://dl.acm.org/citation.cfm?id=1624775.1624804},
year = {1973}
}
@article{Feng2016,
author = {Feng, Dan},
doi = {10.1109/SC.2014.67},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2016/Unknown/Feng/Feng\_2016\_FAST Near Real-time Data Analytics for the Cloud\_Unknown.pdf:pdf},
isbn = {9781450324281},
keywords = {cloud storage,data analytics,due to the unacceptable,latency,mance,of data,often unacceptable latency,real-time perfor-,semantic correlation,severely diminishes the value,the,the staleness of data},
title = {{FAST : Near Real-time Data Analytics for the Cloud}},
year = {2016}
}
@inproceedings{Plagge:2013:UAN:2498328.2500061,
address = {New York, NY, USA},
author = {Plagge, Mark},
booktitle = {Proceedings of the 51st ACM Southeast Conference},
doi = {10.1145/2498328.2500061},
isbn = {978-1-4503-1901-0},
keywords = {artificial neural networks,student retention},
pages = {17:1----17:5},
publisher = {ACM},
series = {ACMSE '13},
title = {{Using Artificial Neural Networks to Predict First-year Traditional Students Second Year Retention Rates}},
url = {http://doi.acm.org/10.1145/2498328.2500061},
year = {2013}
}
@article{Ramadass2012,
author = {Ramadass, Sathya and Abraham, Annamma},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/Unknown/Ramadass, Abraham/Ramadass, Abraham\_2012\_Unsupervised Control Paradigm for Performance Evaluation\_Unknown.pdf:pdf},
keywords = {competitive learning,intelligent control,rule extraction,som,unsupervised learning},
number = {April},
pages = {27--31},
title = {{Unsupervised Control Paradigm for Performance Evaluation}},
volume = {44},
year = {2012}
}
@article{Osborn2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1112.5354v1},
author = {Osborn, James and Javier, Francisco and Juez, De Cos and Guzman, Dani and Butterley, Timothy and Myers, Richard},
eprint = {arXiv:1112.5354v1},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/Unknown/Osborn et al/Osborn et al.\_2011\_open-loop tomography\_Unknown.5354 using artificial neural networks for open-loop tomography:5354 using artificial neural networks for open-loop tomography},
number = {2007},
title = {open-loop tomography},
volume = {312},
year = {2011}
}
@article{Kempe2003,
abstract = {Models for the processes by which ideas and influence propagate through a social network have been studied in a number of do- mains, including the diffusion of medical and technological innovations, the sudden and widespread adoption of various strate gies in game-theoretic settings, and the effects of “word of mouth” in the promotion of new products. Recently , motivated by the design of viral marketingstrategies, Domingos and Richardson posed a fun- damental algorithmic problem for such social netw ork processes: if we can try to con vince a subset of indi viduals to adopt a ne w product or inno v ation, and the goal is to trigger a lar ge cascade of further adoptions, which set of indi viduals should we tar get? W e consider this problem in se v eral of the most widely studied models in social netw ork analysis. The optimization problem of selecting the most influential nodes is NP-hard here, and we provide the first provable approximation guarantees for ef ficient algorithms. Using an analysis frame w ork based on submodular func- tions, we sho w that a natural greedy strate gy obtains a solution that is pro v ably within 63\% of optimal for several classes of models; our frame w rk suggests a general approach for reasoning about the performance guarantees of algorithms for these types of influence problems in social netw orks. W e also pro vide computational e xperiments on lar ge collabora- tion netw orks, sho wing that in addition to their pro v able guaran- tees, our approximation algorithms significantly out-perform node- selection heuristics based on the well-studied notions of de gree centrality and distance centrality from the field of social networks.},
address = {New York, New York, USA},
author = {Kempe, David and Kleinberg, Jon and Tardos, \'{E}va},
doi = {10.1145/956755.956769},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2003/Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '03/Kempe, Kleinberg, Tardos/Kempe, Kleinberg, Tardos\_2003\_Maximizing the spread of influence through a social network\_Proceedings of the ninth ACM SIGKDD internatio.pdf:pdf},
isbn = {1581137370},
journal = {Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '03},
pages = {137},
publisher = {ACM Press},
title = {{Maximizing the spread of influence through a social network}},
url = {http://portal.acm.org/citation.cfm?doid=956750.956769},
year = {2003}
}
@phdthesis{Blanchard2013,
abstract = {For appropriate matrix ensembles, greedy algorithms have proven to be an efficient means of solving the combinatorial optimization problem associated with compressed sensing. This paper describes an implementation for graphics processing units (GPU) of hard thresholding, iterative hard thresholding, normalized iterative hard thresholding, hard thresholding pursuit, and a two-stage thresholding algorithm based on compressive sampling matching pursuit and subspace pursuit. The GPU ac- celeration of the former bottleneck, namely the matrix-vector multiplications, trans- fers a significant portion of the computational burden to the identification of the sup- port set. The software solves high-dimensional problems in fractions of second which permits large-scale testing at dimensions currently unavailable in the literature. The GPU implementations exhibit up to 70x acceleration over standard Matlab central processing unit implementations using automatic multi-threading.},
author = {Blanchard, JD and Tanner, Jared},
booktitle = {Mathematical Programming Computation},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2013/Mathematical Programming Computation/Blanchard, Tanner/Blanchard, Tanner\_2013\_GPU accelerated greedy algorithms for compressed sensing\_Mathematical Programming Computation(2).pdf:pdf},
keywords = {combinatorial optimization,compressed sensing,cosamp,fellow at the university,graphics processing units,greedy algorithms,htp,iht,jdb was a national,niht,of edinburgh,parallel computing,science foundation international research,sparse approxima-,subspace pursuit,tion},
school = {University of Oxford},
title = {{GPU accelerated greedy algorithms for compressed sensing}},
url = {http://link.springer.com/article/10.1007/s12532-013-0056-5},
year = {2013}
}
@article{Lifflander2014,
author = {Lifflander, Jonathan and Kale, Laxmikant V},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/Sc14/Lifflander, Kale/Lifflander, Kale\_2014\_Optimizing Data Locality for Fork Join Programs Using Constrained Work Stealing\_Sc14.pdf:pdf},
isbn = {9781479955008},
journal = {Sc14},
keywords = {cilk,data locality,fork,join,task granularity},
title = {{Optimizing Data Locality for Fork / Join Programs Using Constrained Work Stealing}},
year = {2014}
}
@article{Rast2010,
abstract = {Neural networks present a fundamentally different model of computation from the conventional sequential digital model. Modelling large networks on conventional hardware thus tends to be inefficient if not impossible. Neither dedicated neural chips, with model limitations, nor FPGA implementations, with scalability limitations, offer a satisfactory solution even though they have improved simulation performance dramatically. SpiNNaker introduces a different approach, the "neuromimetic" architecture, that maintains the neural optimisation of dedicated chips while offering FPGA-like universal configurability. Central to this parallel multiprocessor is an asynchronous event-driven model that uses interrupt-generating dedicated hardware on the chip to support real-time neural simulation. While this architecture is particularly suitable for spiking models, it can also implement "classical" neural models like the MLP efficiently. Nonetheless, event handling, particularly servicing incoming packets, requires careful and innovative design in order to avoid local processor congestion and possible deadlock. Using two exemplar models, a spiking network using Izhikevich neurons, and an MLP network, we illustrate how to implement efficient service routines to handle input events. These routines form the beginnings of a library of "drop-in" neural components. Ultimately, the goal is the creation of a library-based development system that allows the modeller to describe a model in a high-level neural description environment of his choice and use an automated tool chain to create the appropriate SpiNNaker instantiation. The complete system: universal hardware, automated tool chain, embedded system management, represents the "ideal" neural modelling environment: a general-purpose platform that can generate an arbitrary neural network and run it with hardware speed and scale. \^{A}© 2010 ACM.},
author = {Rast, A.D. and Jin, X. and Galluppi, F. and Plana, L.a. and Patterson, C. and Furber, S.},
doi = {ISBN:978-1-4503-0044-5},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2010/Proceedings of the 7th ACM international conference on Computing frontiers/Rast et al/Rast et al.\_2010\_Scalable event-driven native parallel processing The spinnaker neuromimetic system\_Proceedings of the 7th ACM internati.pdf:pdf},
isbn = {9781450300445},
journal = {Proceedings of the 7th ACM international conference on Computing frontiers},
number = {June 2015},
pages = {21--30},
title = {{Scalable event-driven native parallel processing: The spinnaker neuromimetic system}},
url = {http://dl.acm.org/citation.cfm?id=1787279},
year = {2010}
}
@article{Amir2013,
abstract = {Marching along the DARPA SyNAPSE roadmap, IBM unveils a trilogy of innovations towards the TrueNorth cognitive computing system inspired by the brain's function and efficiency. The sequential programming paradigm of the von Neumann architecture is wholly unsuited for TrueNorth. Therefore, as our main contribution, we develop a new programming paradigm that permits construction of complex cognitive algorithms and applications while being efficient for TrueNorth and effective for programmer productivity. The programming paradigm consists of (a) an abstraction for a TrueNorth program, named Corelet, for representing a network of neurosynaptic cores that encapsulates all details except external inputs and outputs; (b) an object-oriented Corelet Language for creating, composing, and decomposing corelets; (c) a Corelet Library that acts as an ever-growing repository of reusable corelets from which programmers compose new corelets; and (d) an end-to-end Corelet Laboratory that is a programming environment which integrates with the TrueNorth architectural simulator, Compass, to support all aspects of the programming cycle from design, through development, debugging, and up to deployment. The new paradigm seamlessly scales from a handful of synapses and neurons to networks of neurosynaptic cores of progressively increasing size and complexity. The utility of the new programming paradigm is underscored by the fact that we have designed and implemented more than 100 algorithms as corelets for TrueNorth in a very short time span.},
annote = {Has information on the prog. paradigm involved in True North,},
author = {Amir, Arnon and Datta, Pallab and Risk, William P. and Cassidy, Andrew S. and Kusnitz, Jeffrey a. and Esser, Steve K. and Andreopoulos, Alexander and Wong, Theodore M. and Flickner, Myron and Alvarez-Icaza, Rodrigo and McQuinn, Emmett and Shaw, Ben and Pass, Norm and Modha, Dharmendra S.},
doi = {10.1109/IJCNN.2013.6707078},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2013/Proceedings of the International Joint Conference on Neural Networks/Amir et al/Amir et al.\_2013\_Cognitive computing programming paradigm A Corelet Language for composing networks of neurosynaptic cores\_Proceedings o.pdf:pdf},
isbn = {9781467361293},
journal = {Proceedings of the International Joint Conference on Neural Networks},
number = {December},
title = {{Cognitive computing programming paradigm: A Corelet Language for composing networks of neurosynaptic cores}},
year = {2013}
}
@article{Goldenberg2001,
author = {Goldenberg, Jacob},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2001/Unknown/Goldenberg/Goldenberg\_2001\_Using Complex Systems Analysis to Advance Marketing Theory Development Modeling Heterogeneity Effects on New Product Gr.pdf:pdf},
number = {9},
title = {{Using Complex Systems Analysis to Advance Marketing Theory Development : Modeling Heterogeneity Effects on New Product Growth through Stochastic Cellular Automata USING COMPLEX SYSTEMS ANALYSIS TO ADVANCE MARKETING THEORY DEVELOPMENT : MODELING HETEROGENE}},
volume = {2001},
year = {2001}
}
@article{Gu2012,
author = {Gu, Chun-ming and Ji, Hui},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/Unknown/Gu, Ji/Gu, Ji\_2012\_MRI Brain Image Classification by Artificial Neural Network trained via ABP\_Unknown.pdf:pdf},
keywords = {bp neural network,magnetic resonance imaging,pattern recognition,principle component analysis},
number = {1},
pages = {123--126},
title = {{MRI Brain Image Classification by Artificial Neural Network trained via ABP}},
volume = {2},
year = {2012}
}
@misc{NCenter2012,
author = {{U.S. Department of Education}},
booktitle = {National Center for Education Statistics Home Page},
title = {{The Condition of Education - Postsecondary Education - Completions - Postsecondary Graduation Rates}},
url = {http://nces.ed.gov/programs/coe/indicator\_pgr.asp},
year = {2012}
}
@article{Chen2014,
author = {Chen, Zhengzhang and Son, Seung Woo and Hendrix, William and Agrawal, Ankit and Liao, Wei-keng and Choudhary, Alok},
doi = {10.1109/SC.2014.65},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/SuperComputing/Chen et al/Chen et al.\_2014\_NUMARCK Machine Learning Algorithm for Resiliency and Checkpointing\_SuperComputing.pdf:pdf},
isbn = {978-1-4799-5500-8},
journal = {SuperComputing},
title = {{NUMARCK : Machine Learning Algorithm for Resiliency and Checkpointing}},
year = {2014}
}
@article{Merolla2011,
abstract = {The grand challenge of neuromorphic computation is to develop a flexible brain-like architecture capable of a wide array of real-time applications, while striving towards the ultra-low power consumption and compact size of the human brain\&\#x2014;within the constraints of existing silicon and post-silicon technologies. To this end, we fabricated a key building block of a modular neuromorphic architecture, a neurosynaptic core, with 256 digital integrate-and-fire neurons and a 1024\&\#x00D7;256 bit SRAM crossbar memory for synapses using IBM's 45nm SOI process. Our fully digital implementation is able to leverage favorable CMOS scaling trends, while ensuring one-to-one correspondence between hardware and software. In contrast to a conventional von Neumann architecture, our core tightly integrates computation (neurons) alongside memory (synapses), which allows us to implement efficient fan-out (communication) in a naturally parallel and event-driven manner, leading to ultra-low active power consumption of 45pJ/spike. The core is fully configurable in terms of neuron parameters, axon types, and synapse states and is thus amenable to a wide range of applications. As an example, we trained a restricted Boltzmann machine offline to perform a visual digit recognition task, and mapped the learned weights to our chip.},
author = {Merolla, Paul and Arthur, John and Akopyan, Filipp and Imam, Nabil and Manohar, Rajit and Modha, Dharmendra S.},
doi = {10.1109/CICC.2011.6055294},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2011/Proceedings of the Custom Integrated Circuits Conference/Merolla et al/Merolla et al.\_2011\_A digital neurosynaptic core using embedded crossbar memory with 45pJ per spike in 45nm\_Proceedings of the Custom In.pdf:pdf},
isbn = {9781457702228},
issn = {08865930},
journal = {Proceedings of the Custom Integrated Circuits Conference},
pages = {1--4},
title = {{A digital neurosynaptic core using embedded crossbar memory with 45pJ per spike in 45nm}},
year = {2011}
}
@article{Networks2014a,
author = {Networks, Genome-scale Gene and Misra, Sanchit and Pamnany, Kiran and Chockalingam, Sriram P},
doi = {10.1109/SC.2014.43},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/Unknown/Networks et al/Networks et al.\_2014\_Parallel Bayesian Network Structure Learning for\_Unknown.pdf:pdf},
isbn = {978-1-4799-5500-8},
keywords = {Lecture 14,bayesian networks,chine learning,gene networks,parallel ma-,systems biology},
mendeley-tags = {Lecture 14},
title = {{Parallel Bayesian Network Structure Learning for}},
year = {2014}
}
@article{Herzog2006,
abstract = {Focusing on student retention and time to degree completion, this study illustrates how institutional researchers may benefit from the power of predictive analyses associated with data-mining tools.},
author = {Herzog, Serge},
doi = {10.1002/ir.185},
journal = {New Directions for Institutional Research},
number = {131},
pages = {17--33},
title = {{Estimating student retention and degree-completion time: Decision trees and neural networks vis-\`{a}-vis regression}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/ir.185/abstract},
volume = {2006},
year = {2006}
}
@article{Harish2007,
author = {Harish, Pawan and Narayanan, P J},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/Unknown/Unknown/Harish, Narayanan/Harish, Narayanan\_Unknown\_Accelerating large graph algorithms on the GPU using\_Unknown.pdf:pdf},
title = {{Accelerating large graph algorithms on the GPU using}}
}
@article{Misra2012,
author = {Misra, C. and {K. Swain}, P. and {K. Mantri}, J.},
doi = {10.5120/4927-7156},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2012/International Journal of Computer Applications/Misra, K. Swain, K. Mantri/Misra, K. Swain, K. Mantri\_2012\_Text Extraction and Recognition from Image using Neural Network\_International Journal of Computer Applic.pdf:pdf},
issn = {09758887},
journal = {International Journal of Computer Applications},
keywords = {image,indexing,multimedia,recognition,text extraction},
month = feb,
number = {2},
pages = {13--19},
title = {{Text Extraction and Recognition from Image using Neural Network}},
url = {http://research.ijcaonline.org/volume40/number2/pxc3877156.pdf},
volume = {40},
year = {2012}
}
@article{Kurt2014,
author = {Kurt, Mehmet Can and Krishnamoorthy, Sriram and Agrawal, Kunal and Agrawal, Gagan},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2014/Unknown/Kurt et al/Kurt et al.\_2014\_Fault-Tolerant Dynamic Task Graph Scheduling\_Unknown.pdf:pdf},
isbn = {9781479955008},
keywords = {cilk,dag,fault tolerance,task graphs,work stealing},
title = {{Fault-Tolerant Dynamic Task Graph Scheduling}},
year = {2014}
}
@misc{Hartmann,
annote = {Add authors},
author = {Hartmann, Wesley and Manchanda, Puneet and Nair, Harikesh and Bothner, Matthew},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/Unknown/Unknown/Hartmann et al/Hartmann et al.\_Unknown\_Modeling Social Interactions Identification, empirical methods and policy implications\_Unknown.pdf:pdf},
title = {{Modeling Social Interactions: Identification,
empirical methods and policy implications
}}
}
@article{Rochel2003,
author = {Rochel, Olivier and Martinez, Dominique},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2003/ESANN'2003 Proceedings --European Symposium on Artifical Neural Networks/Rochel, Martinez/Rochel, Martinez\_2003\_An event-driven framework for the simulation of networks of spiking neurons\_ESANN'2003 Proceedings --European Symp.pdf:pdf},
isbn = {293030703X},
journal = {ESANN'2003 Proceedings --European Symposium on Artifical Neural Networks},
number = {JANUARY 2003},
pages = {295--300},
title = {{An event-driven framework for the simulation of networks of spiking neurons}},
year = {2003}
}
@article{Delen2010,
author = {Delen, Dursun},
doi = {10.1016/j.dss.2010.06.003},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2010/Decision Support Systems/Delen/Delen\_2010\_A comparative analysis of machine learning techniques for student retention management\_Decision Support Systems.pdf:pdf},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {retention management},
month = nov,
number = {4},
pages = {498--506},
publisher = {Elsevier B.V.},
title = {{A comparative analysis of machine learning techniques for student retention management}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167923610001041},
volume = {49},
year = {2010}
}
@article{Bazgan2014a,
abstract = {In this paper, we consider the problem of maximizing the spread of influence through a social network. Given a graph with a threshold value thr(v) attached to each vertex v, the spread of influence is modeled as follows: A vertex v becomes "active" (influenced) if at least thr(v) of its neighbors are active. In the corresponding optimization problem the objective is then to find a fixed number k of vertices to activate such that the number of activated vertices at the end of the propagation process is maximum. We show that this problem is strongly inapproximable in time f(k)̇nO(1), for some function f, even for very restrictive thresholds. In the case that the threshold of each vertex equals its degree, we prove that the problem is inapproximable in polynomial time and it becomes r(n)-approximable in time f(k)̇nO(1), for some function f, for any strictly increasing function r. Moreover, we show that the decision version parameterized by k is W[1]-hard but becomes fixed-parameter tractable on bounded degree graphs. © 2014 Elsevier B.V.},
archivePrefix = {arXiv},
arxivId = {arXiv:1303.6907v1},
author = {Bazgan, Cristina and Chopin, Morgan and Nichterlein, Andr\'{e} and Sikora, Florian},
doi = {10.1016/j.jda.2014.05.001},
eprint = {arXiv:1303.6907v1},
isbn = {9783642387678},
issn = {15708667},
journal = {Journal of Discrete Algorithms},
keywords = {Approximation,Dynamic monopolies,Parameterized approximation,Parameterized complexity,Spread of information,Target set selection,Viral marketing},
pages = {54--65},
title = {{Parameterized approximability of maximizing the spread of influence in networks}},
volume = {27},
year = {2014}
}
@article{Bazgan2014,
abstract = {In this paper, we consider the problem of maximizing the spread of influence through a social network. Given a graph with a threshold value thr(v) attached to each vertex v, the spread of influence is modeled as follows: A vertex v becomes "active" (influenced) if at least thr(v) of its neighbors are active. In the corresponding optimization problem the objective is then to find a fixed number k of vertices to activate such that the number of activated vertices at the end of the propagation process is maximum. We show that this problem is strongly inapproximable in time f(k)̇nO(1), for some function f, even for very restrictive thresholds. In the case that the threshold of each vertex equals its degree, we prove that the problem is inapproximable in polynomial time and it becomes r(n)-approximable in time f(k)̇nO(1), for some function f, for any strictly increasing function r. Moreover, we show that the decision version parameterized by k is W[1]-hard but becomes fixed-parameter tractable on bounded degree graphs. © 2014 Elsevier B.V.},
archivePrefix = {arXiv},
arxivId = {arXiv:1303.6907v1},
author = {Bazgan, Cristina and Chopin, Morgan and Nichterlein, Andr\'{e} and Sikora, Florian},
doi = {10.1016/j.jda.2014.05.001},
eprint = {arXiv:1303.6907v1},
isbn = {9783642387678},
issn = {15708667},
journal = {Journal of Discrete Algorithms},
keywords = {Approximation,Dynamic monopolies,Parameterized approximation,Parameterized complexity,Spread of information,Target set selection,Viral marketing},
pages = {54--65},
title = {{Parameterized approximability of maximizing the spread of influence in networks}},
volume = {27},
year = {2014}
}
@article{Chen2010a,
author = {Chen, Wei and Wang, Chi and Wang, Yajun},
file = {:Users/Mark/Dropbox/Research/RPI/ResearchDocs/2010/Unknown/Chen, Wang, Wang/Chen, Wang, Wang\_2010\_Scalable Influence Maximization for Prevalent Viral Marketing in Large-Scale Social Networks ∗ Microsoft Researc.pdf:pdf},
keywords = {influence maximization,social networks,viral},
number = {January},
title = {{Scalable Influence Maximization for Prevalent Viral Marketing in Large-Scale Social Networks ∗ Microsoft Research Technical Report}},
year = {2010}
}
